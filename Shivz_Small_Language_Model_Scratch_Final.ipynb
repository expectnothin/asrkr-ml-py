{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/expectnothin/asrkr-ml-py/blob/main/Shivz_Small_Language_Model_Scratch_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijDG3IDqkjKx"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Let us build a Small Language Model (SLM) from scratch. We will try to keep the parameter size to 10-15 million.\n",
        "\n",
        "Our goal is to generate creative and coherent text based on the input data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPl23BNsRqfm"
      },
      "source": [
        "## Step 1: Import the Dataset\n",
        "\n",
        "TinyStories is a synthetic dataset of short stories that only contain words that a typical 3 to 4-year-olds usually understand, generated by GPT-3.5 and GPT-4. We can get it from HuggingFace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSeXbOztRtKN"
      },
      "outputs": [],
      "source": [
        "!pip install -U datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkpPWqR8-tFO"
      },
      "outputs": [],
      "source": [
        "# Removed redundant pip install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOcLKbZBi648",
        "outputId": "579e601e-f040-4728-c2ba-8edf80b0029d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".config\n",
            "test.bin\n",
            "TinyStories\n",
            "train.bin\n",
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# List all files in the current directory\n",
        "for f in os.listdir():\n",
        "    print(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3o5BEWyFjcEx"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/TinyStories/train.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0NXpg9HjeeX"
      },
      "outputs": [],
      "source": [
        "!ls -lh /content/TinyStories\n",
        "\n",
        "import json\n",
        "\n",
        "input_file = \"/content/TinyStories/TinyStories-train.txt\"\n",
        "output_file = \"/content/TinyStories/train.jsonl\"\n",
        "\n",
        "with open(input_file, \"r\") as f_in, open(output_file, \"w\") as f_out:\n",
        "    for line in f_in:\n",
        "        f_out.write(json.dumps({\"text\": line.strip()}) + \"\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl1G1zOOpVvu",
        "outputId": "d57afd14-4096-4eb3-d441-c0ae947a0ac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"text\": \"One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\"}\n",
            "{\"text\": \"Lily went to her mom and said, \\\"Mom, I found this needle. Can you share it with me and sew my shirt?\\\" Her mom smiled and said, \\\"Yes, Lily, we can share the needle and fix your shirt.\\\"\"}\n",
            "{\"text\": \"Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\"}\n",
            "{\"text\": \"<|endoftext|>\"}\n",
            "{\"text\": \"Once upon a time, there was a little car named Beep. Beep loved to go fast and play in the sun. Beep was a healthy car because he always had good fuel. Good fuel made Beep happy and strong.\"}\n",
            "{\"text\": \"One day, Beep was driving in the park when he saw a big tree. The tree had many leaves that were falling. Beep liked how the leaves fall and wanted to play with them. Beep drove under the tree and watched the leaves fall on him. He laughed and beeped his horn.\"}\n",
            "{\"text\": \"Beep played with the falling leaves all day. When it was time to go home, Beep knew he needed more fuel. He went to the fuel place and got more healthy fuel. Now, Beep was ready to go fast and play again the next day. And Beep lived happily ever after.\"}\n",
            "{\"text\": \"<|endoftext|>\"}\n",
            "{\"text\": \"One day, a little fish named Fin was swimming near the shore. He saw a big crab and wanted to be friends. \\\"Hi, I am Fin. Do you want to play?\\\" asked the little fish. The crab looked at Fin and said, \\\"No, I don't want to play. I am cold and I don't feel fine.\\\"\"}\n",
            "{\"text\": \"Fin felt sad but wanted to help the crab feel better. He swam away and thought of a plan. He remembered that the sun could make things warm. So, Fin swam to the top of the water and called to the sun, \\\"Please, sun, help my new friend feel fine and not freeze!\\\"\"}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 2119719\n",
            "})\n",
            "Type: <class 'datasets.arrow_dataset.Dataset'>\n",
            "Number of rows: 2119719\n",
            "Column names: ['text']\n",
            "First example:\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets --upgrade --quiet\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from datasets.utils.logging import disable_progress_bar\n",
        "disable_progress_bar()\n",
        "\n",
        "!head /content/TinyStories/train.jsonl\n",
        "\n",
        "from datasets import Dataset\n",
        "myds = Dataset.from_json(\"/content/TinyStories/train.jsonl\")\n",
        "\n",
        "myds = load_dataset(\"roneneldan/TinyStories\", split=\"train\")\n",
        "print(myds)\n",
        "\n",
        "# You can also print summary manually:\n",
        "print(f\"Type: {type(myds)}\")\n",
        "print(f\"Number of rows: {len(myds)}\")\n",
        "print(f\"Column names: {myds.column_names}\")\n",
        "print(\"First example:\")\n",
        "\n",
        "\n",
        "#print(myds[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nj26oD4uPOPC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYbCc-f1pXbj"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "dataset = Dataset.from_json(\"/content/TinyStories/train.jsonl\")\n",
        "dataset = dataset.train_test_split(test_size=0.1)\n",
        "\n",
        "# Step 3: Save to disk (folder format)\n",
        "train_ds.save_to_disk(\"train_dataset\")\n",
        "test_ds.save_to_disk(\"test_dataset\")\n",
        "\n",
        "# Step 4: Archive to .bin format\n",
        "shutil.make_archive(\"train_dataset\", \"zip\", \"train_dataset\")\n",
        "shutil.make_archive(\"test_dataset\", \"zip\", \"test_dataset\")\n",
        "\n",
        "# Step 5: Rename .zip to .bin\n",
        "os.rename(\"train_dataset.zip\", \"train_dataset.bin\")\n",
        "os.rename(\"test_dataset.zip\", \"test_dataset.bin\")\n",
        "\n",
        "print(dataset)\n",
        "print(dataset[\"train\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GddZuZ0TDdqS",
        "outputId": "eb0429d9-8597-4636-9f09-e29f97a01f10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 13333941\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 1481549\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rNqveXDEP2q",
        "outputId": "cacdf21f-3eee-4a30-bb18-3ad1d1371e39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Saved as train_dataset.bin and val_dataset.bin\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset, load_from_disk\n",
        "import shutil, os\n",
        "\n",
        "# Step 1: Load from JSONL\n",
        "dataset = Dataset.from_json(\"/content/TinyStories/train.jsonl\")\n",
        "\n",
        "# Step 2: Split into train and validation\n",
        "split_dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
        "train_ds = split_dataset[\"train\"]\n",
        "val_ds = split_dataset[\"test\"]\n",
        "\n",
        "# Step 3: Save to folders\n",
        "train_ds.save_to_disk(\"train_dataset\")\n",
        "val_ds.save_to_disk(\"val_dataset\")\n",
        "\n",
        "# Step 4: Archive as .bin files (just zipped folders with .bin extension)\n",
        "shutil.make_archive(\"train_dataset\", \"zip\", \"train_dataset\")\n",
        "shutil.make_archive(\"val_dataset\", \"zip\", \"val_dataset\")\n",
        "\n",
        "# Step 5: Rename .zip ‚Üí .bin\n",
        "os.rename(\"train_dataset.zip\", \"train_dataset.bin\")\n",
        "os.rename(\"val_dataset.zip\", \"val_dataset.bin\")\n",
        "\n",
        "print(\"‚úÖ Saved as train_dataset.bin and val_dataset.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9v6YT-2tCds"
      },
      "outputs": [],
      "source": [
        "!ls -lh /content/TinyStories/train.jsonl\n",
        "!head /content/TinyStories/train.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRxgf1_fkiFX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nrju4oIPh3Ln"
      },
      "outputs": [],
      "source": [
        "!apt-get install git-lfs\n",
        "!git lfs install\n",
        "\n",
        "%cd /content/\n",
        "!git clone https://huggingface.co/datasets/roneneldan/TinyStories\n",
        "%cd TinyStories\n",
        "!git lfs pull\n",
        "\n",
        "!ls -lh /content/TinyStories\n",
        "\n",
        "from datasets import load_dataset\n",
        "!rm -rf ~/.cache/huggingface/datasets\n",
        "!rm -rf ~/.cache/huggingface/hub\n",
        "!rm -rf ./tmp_dataset_cache\n",
        "\n",
        "!ls -lh /content/TinyStories\n",
        "\n",
        "# ds = load_dataset(\"roneneldan/TinyStories\", download_mode=\"force_redownload\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vccyr4qKR6OH"
      },
      "source": [
        "## Step 2: Tokenize the Dataset\n",
        "\n",
        "In this step, we will do the following:\n",
        "\n",
        "(1) Tokenize the dataset into tokenIDs.\n",
        "\n",
        "(2) Create a file called \"train.bin\" and \"validtion.bin\" where we will store the tokenIDs from the entire dataset.\n",
        "\n",
        "(3) We make sure the tokenIDs are stored on a disk, rather than on the RAM for efficient computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhRb2KEfHCQp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.rename(\"train_dataset.bin\", \"train_dataset.zip\")\n",
        "os.rename(\"val_dataset.bin\", \"val_dataset.zip\")\n",
        "\n",
        "import shutil\n",
        "from datasets import load_from_disk, concatenate_datasets\n",
        "\n",
        "shutil.unpack_archive(\"train_dataset.zip\", \"train_dataset\")\n",
        "shutil.unpack_archive(\"val_dataset.zip\", \"val_dataset\")\n",
        "\n",
        "train_ds = load_from_disk(\"train_dataset\")\n",
        "val_ds = load_from_disk(\"val_dataset\")\n",
        "\n",
        "# Reunite them (if you want full dataset back together)\n",
        "full_ds = concatenate_datasets([train_ds, val_ds])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVUh5sECLto9"
      },
      "outputs": [],
      "source": [
        "def inspect_dataset(ds):\n",
        "    from datasets import Dataset, DatasetDict\n",
        "\n",
        "    if isinstance(ds, DatasetDict):\n",
        "        print(f\"üì¶ DatasetDict with {len(ds)} splits:\\n\")\n",
        "        for split_name, split in ds.items():\n",
        "            print(f\"üîπ Split: {split_name}\")\n",
        "            print(f\"   üëâ Rows: {len(split)}\")\n",
        "            print(f\"   üëâ Columns: {split.column_names}\")\n",
        "            print(f\"   üëâ Example[0]: {split[0]}\\n\")\n",
        "\n",
        "    elif isinstance(ds, Dataset):\n",
        "        print(f\"üì¶ Single Dataset:\")\n",
        "        print(f\"   üëâ Rows: {len(ds)}\")\n",
        "        print(f\"   üëâ Columns: {ds.column_names}\")\n",
        "        print(f\"   üëâ Example[0]: {ds[0]}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Not a Hugging Face Dataset or DatasetDict.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju5ZifTdMTrP",
        "outputId": "d7bb95ff-5553-4bb4-db29-89038a2f3363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ DatasetDict with 2 splits:\n",
            "\n",
            "üîπ Split: train\n",
            "   üëâ Rows: 1907747\n",
            "   üëâ Columns: ['text']\n",
            "   üëâ Example[0]: {'text': 'Anna and Ben went to the park with Mom. They liked to play on the swings and slide. They also liked to feed the ducks in the pond. Mom gave them some bread to share with the ducks.\\n\\nThey saw a big duck with a green head and a brown body. He looked hungry, so Anna threw him a piece of bread. But he did not eat it. He quacked loudly and chased the other ducks away. He wanted all the bread for himself.\\n\\n\"Stop it, duck!\" Ben said. \"You are rude. You have to share with the others.\"\\n\\nThe duck did not listen. He kept quacking and biting the other ducks. He made them sad and scared. Anna and Ben felt sorry for them.\\n\\n\"Mom, can we help the other ducks?\" Anna asked.\\n\\nMom nodded. She took a stick and waved it at the rude duck. She said, \"Shoo, shoo, go away. You are not nice. Leave the other ducks alone.\"\\n\\nThe rude duck saw the stick and got scared. He stopped quacking and biting. He swam away to the other side of the pond. He did not bother the other ducks anymore.\\n\\nAnna and Ben smiled. They threw the rest of the bread to the other ducks. The other ducks ate it happily. They quacked softly and thanked Anna and Ben.\\n\\nAnna and Ben felt happy too. They said, \"You are welcome, ducks. We are glad you are not sad and scared anymore.\"\\n\\nThey waved goodbye to the ducks and went back to play on the swings and slide. They had fun at the park.'}\n",
            "\n",
            "üîπ Split: test\n",
            "   üëâ Rows: 211972\n",
            "   üëâ Columns: ['text']\n",
            "   üëâ Example[0]: {'text': 'Once upon a time, there was a bald bear who was wandering through a big forest. He looked around but he couldn\\'t find anything to eat. He went further into the forest and he saw an old tree with a strange hollow. \\n\\nThe bear went inside and he found a pot filled with delicious honey! He was so happy. He opened his mouth to start eating it. \\n\\nBut then, a voice from above the tree said, \"Who\\'s there? That honey is my reward! You cannot have it!\"\\n\\nThe bear was very scared. He tried to speak but he was so scared that he couldn\\'t say anything. It was an old bad witch! \\n\\n\"You must leave now or I\\'ll cast a nasty spell on you!\" said the witch. \\n\\nThe bear knew that he had no choice, so he ran out of the forest and never saw the reward again.'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inspect_dataset()split_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61s6VpxvHlJ0"
      },
      "outputs": [],
      "source": [
        "full_ds.save_to_disk(\"full_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMxFV8vTH1_L"
      },
      "outputs": [],
      "source": [
        "import shutil, os\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive(\"full_dataset\", \"zip\", \"full_dataset\")\n",
        "\n",
        "# Rename to .bin if you prefer binary-style naming\n",
        "os.rename(\"full_dataset.zip\", \"full_dataset.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "76f4900640c241c8bc916b62b4fb56ce",
            "71310bb680fc4bb69f68f053a0559b89",
            "684f6e6961bc4201a16ffefc1e590289",
            "121620c501b24f58af8e0282b0ceda33",
            "38b881829909433ebcea93179d3d2600",
            "bfc76d9f02044337be18f47d603a420a",
            "877eef285bba4968802eb72180bd5490",
            "8d13967860bc457f890b1c6d97989590",
            "91668d5ffca24bcc9fea9b145fc3831c",
            "9871591e8711448cb6225b312a098538",
            "d203663e28d04bb780c045d6bb8410d6",
            "1b1b00f741444ab185bc11ff5a116921",
            "5ef785743f3a488c9e44e9bd41861a32",
            "7e1305a8e57f489ebd6da294ef7a831a",
            "bc445234dddd4b96ae34cc9d1a4216d2",
            "2f61373f259a453fb9e1c2fdb039e3e2",
            "34d935e5699444d688409a6ef0f56bbc",
            "2d1b73b98add4f1aa23cf23101cccb69",
            "df1e002585b3447cb3cb92d046f7c461",
            "b5f2b35c25834b21a4f7a1f64fa53b2e",
            "702a947bdb6b432592bfc422cbabbc7f",
            "b488d7e92874403f8ca3204e7eb0880b"
          ]
        },
        "id": "vFkgAjyMR8fa",
        "outputId": "e6cb86c2-86e3-4b05-9c5e-4520fa64afb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.7.14)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76f4900640c241c8bc916b62b4fb56ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "writing train.bin:   0%|          | 0/1024 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b1b00f741444ab185bc11ff5a116921",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "writing test.bin:   0%|          | 0/1024 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install tiktoken\n",
        "import tiktoken\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "\n",
        "\n",
        "# Some functions from https://github.com/karpathy/nanoGPT/blob/master/data/openwebtext/prepare.py\n",
        "\n",
        "def process(example):\n",
        "    ids = enc.encode_ordinary(example['text']) # encode_ordinary ignores any special tokens\n",
        "    out = {'ids': ids, 'len': len(ids)}\n",
        "    return out\n",
        "\n",
        "if not os.path.exists(\"train.bin\"):\n",
        "    tokenized = split_ds.map(\n",
        "        process,\n",
        "        remove_columns=['text'],\n",
        "        desc=\"tokenizing the splits\",\n",
        "        num_proc=8,\n",
        "        )\n",
        "    # concatenate all the ids in each dataset into one large file we can use for training\n",
        "    for split, dset in tokenized.items():\n",
        "        arr_len = np.sum(dset['len'], dtype=np.uint64)\n",
        "        filename = f'{split}.bin'\n",
        "        dtype = np.uint16 # (can do since enc.max_token_value == 50256 is < 2**16)\n",
        "        arr = np.memmap(filename, dtype=dtype, mode='w+', shape=(arr_len,))\n",
        "        total_batches = 1024\n",
        "\n",
        "        idx = 0\n",
        "        for batch_idx in tqdm(range(total_batches), desc=f'writing {filename}'):\n",
        "            # Batch together samples for faster write\n",
        "            batch = dset.shard(num_shards=total_batches, index=batch_idx, contiguous=True).with_format('numpy')\n",
        "            arr_batch = np.concatenate(batch['ids'])\n",
        "            # Write into mmap\n",
        "            arr[idx : idx + len(arr_batch)] = arr_batch\n",
        "            idx += len(arr_batch)\n",
        "        arr.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9zs5i7HVkCp"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "split_ds = myds.train_test_split(test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI_W5VEiLcuH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "f6e477bb2f64409cae97c6bd77cb097e",
            "5d9644e7af6647cfb12e97cf1d567b46",
            "2698092978b5483bbf4fcc4f249c44d3",
            "e6464914ded442f8b6d00d61e36be544",
            "683583c2734545c49bb2a4b9dbd597f0",
            "a97a3703110d42e0b91219ccfa8c8fc4",
            "2923c0582d4d4e8c9970632bff0e2398",
            "fc647eb3702b4d4a8277a797c101c446",
            "7815db21ab414d2780d01fb888d24429",
            "7a9128601ef04a1799d07b1b6320452e",
            "d86df11a6f1546feb30a3c930212d9fd",
            "62a01500ccae4c739a42b12022f8ce43",
            "5e25bd75ee844e589732d96f129607c5",
            "124fe82a766d48199ded978cfd6b64bc",
            "19e631fae52a442b886e36500020b32a",
            "56e51145d5384edb87a4ead6ca9adbbf",
            "e56b01c7ceb8409f96548ffc41514174",
            "b50b9c65606a409681d1569f7863d813",
            "620dc645841241a6b86550bf5884ed09",
            "b49edfa15e2445ab812be37f6364d555",
            "11bafebaed264db0936051e26d43b6e5",
            "b4dbf2c06ec04d2194e1c2baefa3ffac"
          ]
        },
        "id": "kPx6WN9N0gy5",
        "outputId": "bd70e66e-a2ad-4043-8b6b-9cf84d2b4f0b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6e477bb2f64409cae97c6bd77cb097e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/14075 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62a01500ccae4c739a42b12022f8ce43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/741 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "import random\n",
        "\n",
        "# Load the giant dataset\n",
        "full_dataset = Dataset.from_json(\"/content/TinyStories/train.jsonl\")\n",
        "\n",
        "# Set seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# Shuffle and split\n",
        "full_dataset = full_dataset.shuffle(seed=42)\n",
        "split_datasets = full_dataset.train_test_split(test_size=0.05)\n",
        "\n",
        "# Save them to disk if needed\n",
        "split_datasets['train'].to_json(\"/content/TinyStories/train_split.jsonl\")\n",
        "split_datasets['test'].to_json(\"/content/TinyStories/val_split.jsonl\")\n",
        "\n",
        "# Wrap into DatasetDict\n",
        "dataset = DatasetDict({\n",
        "    \"train\": split_datasets['train'],\n",
        "    \"validation\": split_datasets['test']\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afaEj3JZxuzU",
        "outputId": "1b3e1209-86a3-41a1-f0c4-60de9282f529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Jul 23 15:19:38 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "M8uUYyUf4CRE",
        "outputId": "bf783b58-3b77-4773-966a-449445970854"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Copy of Vizuara AI Labs Small Language Model Scratch Final.ipynb'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-2288362206.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnotebook_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Copy of Vizuara AI Labs Small Language Model Scratch Final.ipynb\"\u001b[0m  \u001b[0;31m# replace with your file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Copy of Vizuara AI Labs Small Language Model Scratch Final.ipynb'"
          ]
        }
      ],
      "source": [
        "import nbformat\n",
        "from google.colab import files\n",
        "\n",
        "# Load the notebook\n",
        "notebook_filename = \"Copy of Vizuara AI Labs Small Language Model Scratch Final.ipynb\"  # replace with your file name\n",
        "with open(notebook_filename, \"r\") as f:\n",
        "    nb = nbformat.read(f, as_version=4)\n",
        "\n",
        "# Clean up metadata.widgets if broken\n",
        "for cell in nb.cells:\n",
        "    if 'metadata' in cell and 'widgets' in cell['metadata']:\n",
        "        if 'state' not in cell['metadata']['widgets']:\n",
        "            del cell['metadata']['widgets']\n",
        "\n",
        "# Save cleaned notebook\n",
        "fixed_filename = \"fixed_\" + notebook_filename\n",
        "with open(fixed_filename, \"w\") as f:\n",
        "    nbformat.write(nb, f)\n",
        "\n",
        "# Download it (or push to GitHub manually)\n",
        "files.download(fixed_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_qRtn_WSbV4"
      },
      "source": [
        "## Step 3: Create Input-Output batches for the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gak79CZESkjN"
      },
      "outputs": [],
      "source": [
        "# Some functions from https://github.com/karpathy/nanoGPT/blob/master/train.py with slight modifications\n",
        "def get_batch(split):\n",
        "    # We recreate np.memmap every batch to avoid a memory leak, as per\n",
        "    # https://stackoverflow.com/questions/45132940/numpy-memmap-memory-usage-want-to-iterate-once/61472122#61472122\n",
        "    if split == 'train':\n",
        "        data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n",
        "    else:\n",
        "        data = np.memmap('validation.bin', dtype=np.uint16, mode='r')\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
        "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
        "    if device_type == 'cuda':\n",
        "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
        "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
        "    else:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "\n",
        "        print(\"x sample:\", x[0])        # First image tensor\n",
        "\n",
        "    return x, y\n",
        "\n",
        "    x, y = get_batch(\"train\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NniUuAs_erBD",
        "outputId": "4bfb6857-16d5-424a-a198-8868c135da12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üöÄ get_batch called with split='train'\n",
            "Loaded train.bin, length: 424691083\n",
            "Sample indices: tensor([138892052,  29316256, 356103290, 407148769])\n",
            "‚úÖ Batch tensors created\n",
            "x sample: tensor([30697,  1978,   329, 12607,    13,  1273,  2007,   318,   257,  3290])\n",
            "y sample: tensor([ 1978,   329, 12607,    13,  1273,  2007,   318,   257,  3290,   508])\n",
            "X shape: torch.Size([4, 128])\n",
            "Y shape: torch.Size([4, 128])\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.7.14)\n",
            "Decoded X[0]: affle together for breakfast.Stitch is a dog who likes to mark his toys. He has a ball, a bone, a rope and a duck. He marks them with his teeth and his smell. He thinks they are his and no one can take them.\n",
            "\n",
            "One day, a new dog comes to his house. His name is Spot. Spot is big and crazy. He likes to run and jump and bark. He sees Stitch's toys and wants to play with them. He does not know they are marked.\n",
            "\n",
            "Stitch is angry when he sees Spot with his toys. He growls and runs to him\n",
            "Decoded Y[0]:  together for breakfast.Stitch is a dog who likes to mark his toys. He has a ball, a bone, a rope and a duck. He marks them with his teeth and his smell. He thinks they are his and no one can take them.\n",
            "\n",
            "One day, a new dog comes to his house. His name is Spot. Spot is big and crazy. He likes to run and jump and bark. He sees Stitch's toys and wants to play with them. He does not know they are marked.\n",
            "\n",
            "Stitch is angry when he sees Spot with his toys. He growls and runs to him.\n"
          ]
        }
      ],
      "source": [
        "# Define the function first\n",
        "def get_batch(split):\n",
        "    import numpy as np\n",
        "    import torch\n",
        "\n",
        "    block_size = 128\n",
        "    batch_size = 4\n",
        "    device = 'cpu'\n",
        "    device_type = 'cpu'  # Change to 'cuda' if GPU\n",
        "\n",
        "    print(f\"\\nüöÄ get_batch called with split='{split}'\")\n",
        "    data_file = 'train.bin' if split == 'train' else 'validation.bin'\n",
        "\n",
        "    try:\n",
        "        data = np.memmap(data_file, dtype=np.uint16, mode='r')\n",
        "        print(f\"Loaded {data_file}, length: {len(data)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error loading memmap: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    if len(data) < block_size + 1:\n",
        "        print(f\"üö´ Not enough data in {data_file} to create a block of size {block_size}\")\n",
        "        return None, None\n",
        "\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    print(f\"Sample indices: {ix[:5]}\")\n",
        "\n",
        "    try:\n",
        "        x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
        "        y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error stacking batches: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    if device_type == 'cuda':\n",
        "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
        "    else:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "    print(\"‚úÖ Batch tensors created\")\n",
        "    print(\"x sample:\", x[0][:10])\n",
        "    print(\"y sample:\", y[0][:10])\n",
        "    return x, y\n",
        "\n",
        "# CALL IT\n",
        "x, y = get_batch(\"train\")\n",
        "\n",
        "# IF SUCCESSFUL, PRINT SHAPE\n",
        "if x is not None:\n",
        "    print(\"X shape:\", x.shape)\n",
        "    print(\"Y shape:\", y.shape)\n",
        "\n",
        "    !pip install tiktoken\n",
        "import tiktoken\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "def decode(token_list):\n",
        "    return enc.decode(token_list)\n",
        "\n",
        "# Removing the lines calling decode as the function is not defined and not essential for this step.\n",
        "print(\"Decoded X[0]:\", decode(x[0].tolist()))\n",
        "print(\"Decoded Y[0]:\", decode(y[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA1SVp1hkjKy"
      },
      "source": [
        "## Step 4: Define the SLM Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9friaxWABOA-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from contextlib import nullcontext\n",
        "import os\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, ndim, bias):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(ndim))\n",
        "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
        "    def forward(self, x):\n",
        "        return F.layer_norm(x, self.weight.shape, self.weight, self.bias, 1e-5)\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.attn_dropout = nn.Dropout(config.dropout)\n",
        "        self.resid_dropout = nn.Dropout(config.dropout)\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.flash = hasattr(F, 'scaled_dot_product_attention')\n",
        "        if not self.flash:\n",
        "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                       .view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "\n",
        "        if self.flash:\n",
        "            y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.attn_dropout.p if self.training else 0.0, is_causal=True)\n",
        "        else:\n",
        "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "            att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n",
        "            att = F.softmax(att, dim=-1)\n",
        "            att = self.attn_dropout(att)\n",
        "            y = att @ v\n",
        "\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    def forward(self, x):\n",
        "        return self.dropout(self.c_proj(self.gelu(self.c_fc(x))))\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln1 = LayerNorm(config.n_embd, config.bias)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln2 = LayerNorm(config.n_embd, config.bias)\n",
        "        self.mlp = MLP(config)\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int\n",
        "    vocab_size: int\n",
        "    n_layer: int\n",
        "    n_head: int\n",
        "    n_embd: int\n",
        "    dropout: float = 0.0\n",
        "    bias: bool = True\n",
        "\n",
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte=nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe=nn.Embedding(config.block_size, config.n_embd),\n",
        "            drop=nn.Dropout(config.dropout),\n",
        "            h=nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f=LayerNorm(config.n_embd, config.bias),\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        self.transformer.wte.weight = self.lm_head.weight  # weight tying\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                nn.init.normal_(p, mean=0.0, std=0.02 / math.sqrt(2 * config.n_layer))\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.config.block_size\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device)\n",
        "\n",
        "        tok_emb = self.transformer.wte(idx)\n",
        "        pos_emb = self.transformer.wpe(pos)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            logits = self.lm_head(x)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
        "            return logits, loss\n",
        "        else:\n",
        "            logits = self.lm_head(x[:, [-1], :])\n",
        "            return logits, None\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
        "        \"\"\"\n",
        "        Generate tokens given a conditioning sequence.\n",
        "        idx: Tensor of shape (B, T)\n",
        "        \"\"\"\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "            logits, _ = self(idx_cond)\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh6cs83-igCD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-20T15:36:54.88378Z",
          "iopub.status.busy": "2024-06-20T15:36:54.883342Z",
          "iopub.status.idle": "2024-06-20T15:37:07.278493Z",
          "shell.execute_reply": "2024-06-20T15:37:07.277342Z",
          "shell.execute_reply.started": "2024-06-20T15:36:54.883753Z"
        },
        "id": "uRm6WlvfkjKz"
      },
      "outputs": [],
      "source": [
        "config = GPTConfig(\n",
        "    vocab_size=50257,     # use the tokenizer's vocab size\n",
        "    block_size=128,       # or whatever context size you're training with\n",
        "    n_layer=6,\n",
        "    n_head=6,\n",
        "    n_embd=384,\n",
        "    dropout=0.1,\n",
        "    bias=True\n",
        ")\n",
        "\n",
        "model = GPT(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_a8Rd-0S_WC"
      },
      "source": [
        "## Step 5: Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "La2Aun_nTBzk"
      },
      "outputs": [],
      "source": [
        "def estimate_loss(model):\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for split in ['train', 'val']:\n",
        "            losses = torch.zeros(eval_iters)\n",
        "            for k in range(eval_iters):\n",
        "                X, Y = get_batch(split)\n",
        "                with ctx:\n",
        "                    logits, loss = model(X, Y)\n",
        "                losses[k] = loss.item()\n",
        "            out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvqWPUstTRXO"
      },
      "source": [
        "## Step 6: Define SLM Training Configuration Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QQyayhnkjK5",
        "outputId": "f0fe5364-9079-4e21-ccd2-28c345843035"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7852bcd8f770>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training Config\n",
        "import torch\n",
        "from contextlib import nullcontext\n",
        "\n",
        "learning_rate = 1e-4 #more stable training, earlier 1e-4\n",
        "max_iters = 20000 #increase from 25000\n",
        "warmup_steps = 1000 #smoother initial train, earlier 100\n",
        "min_lr = 5e-4 #lower rate, earlier 5e-4\n",
        "eval_iters = 500 # increased from 100\n",
        "batch_size = 32 # changed from 16, better gradient estimate\n",
        "block_size = 128 #changed from 64, capture longer range dependencies\n",
        "\n",
        "gradient_accumulation_steps = 32 # reduced from 50\n",
        "\n",
        "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
        "# note: float16 data type will automatically use a GradScaler\n",
        "\n",
        "# How to use autocast https://wandb.ai/wandb_fc/tips/reports/How-To-Use-Autocast-in-PyTorch--VmlldzoyMTk4NTky\n",
        "#dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
        "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
        "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
        "\n",
        "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
        "\n",
        "torch.set_default_device(device)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmWj6YcKTW_z"
      },
      "source": [
        "## Step 7: Define SLM Training Configuration Part 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMkO3FlNkjK6",
        "outputId": "94b8c3c3-8cc9-4e1a-b1f7-8ac64f706e25"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-a9032b47f003>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import LinearLR,SequentialLR, CosineAnnealingLR\n",
        "\n",
        "##PUT IN WEIGHT DECAY, CHANGED BETA2 to 0.95\n",
        "optimizer =  torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1, eps=1e-9) #weight decay for regularization\n",
        "\n",
        "scheduler_warmup = LinearLR(optimizer, total_iters = warmup_steps) #Implement linear warmup\n",
        "scheduler_decay = CosineAnnealingLR(optimizer,T_max = max_iters - warmup_steps, eta_min = min_lr) #Implement lr decay\n",
        "scheduler = SequentialLR(optimizer, schedulers=[scheduler_warmup, scheduler_decay], milestones=[warmup_steps]) #Switching from warmup to decay\n",
        "\n",
        "# https://stackoverflow.com/questions/72534859/is-gradscaler-necessary-with-mixed-precision-training-with-pytorch\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz8fPSKNTY3W"
      },
      "source": [
        "## Step 8: Pre-train the SLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5e308879faac4365ba172205c84e83e1",
            "e08c8d5cb7d34620a20a4f9e1434f596",
            "4df0870113914b118fc9a1fa223e9386",
            "886e91c4e0974fd6848f051f7cc0bc90",
            "d34f594438bc42ffb64820d383c65a21",
            "bf3293a7a5d4437486c89e2bf12550a4",
            "41431326176b48f8bbb325c78b1bfafc",
            "86c06e5cb98e46c5b638ccb3c9b7ddab",
            "f34d4b7153d64f2ebd8878aef5ef31b0",
            "6c7ef71452e44376a6cf9eaaf36994d3",
            "eda6aac71b62411b99c738029695f91c"
          ]
        },
        "id": "t0l-YhockjK6",
        "outputId": "f77b5cf9-e9a7-4359-83e5-1de8f088a36b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e308879faac4365ba172205c84e83e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 500: train loss 9.4897, val loss 9.4957\n",
            "The current learning rate: 0.00007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1000: train loss 8.5043, val loss 8.5077\n",
            "The current learning rate: 0.00010\n",
            "Epoch 1500: train loss 7.5694, val loss 7.5678\n",
            "The current learning rate: 0.00010\n",
            "Epoch 2000: train loss 6.7185, val loss 6.7158\n",
            "The current learning rate: 0.00010\n",
            "Epoch 2500: train loss 6.0202, val loss 6.0208\n",
            "The current learning rate: 0.00011\n",
            "Epoch 3000: train loss 5.4947, val loss 5.4944\n",
            "The current learning rate: 0.00011\n",
            "Epoch 3500: train loss 5.0635, val loss 5.0636\n",
            "The current learning rate: 0.00012\n",
            "Epoch 4000: train loss 4.7260, val loss 4.7253\n",
            "The current learning rate: 0.00012\n",
            "Epoch 4500: train loss 4.4872, val loss 4.4745\n",
            "The current learning rate: 0.00013\n",
            "Epoch 5000: train loss 4.2713, val loss 4.2802\n",
            "The current learning rate: 0.00014\n",
            "Epoch 5500: train loss 4.0990, val loss 4.0995\n",
            "The current learning rate: 0.00015\n",
            "Epoch 6000: train loss 3.9773, val loss 3.9743\n",
            "The current learning rate: 0.00016\n",
            "Epoch 6500: train loss 3.8234, val loss 3.8265\n",
            "The current learning rate: 0.00018\n",
            "Epoch 7000: train loss 3.7000, val loss 3.7021\n",
            "The current learning rate: 0.00019\n",
            "Epoch 7500: train loss 3.5877, val loss 3.5922\n",
            "The current learning rate: 0.00020\n",
            "Epoch 8000: train loss 3.4900, val loss 3.4920\n",
            "The current learning rate: 0.00022\n",
            "Epoch 8500: train loss 3.3953, val loss 3.4047\n",
            "The current learning rate: 0.00024\n",
            "Epoch 9000: train loss 3.3121, val loss 3.3127\n",
            "The current learning rate: 0.00025\n",
            "Epoch 9500: train loss 3.2394, val loss 3.2417\n",
            "The current learning rate: 0.00027\n",
            "Epoch 10000: train loss 3.1679, val loss 3.1725\n",
            "The current learning rate: 0.00028\n",
            "Epoch 10500: train loss 3.1003, val loss 3.1015\n",
            "The current learning rate: 0.00030\n",
            "Epoch 11000: train loss 3.0328, val loss 3.0379\n",
            "The current learning rate: 0.00032\n",
            "Epoch 11500: train loss 2.9726, val loss 2.9808\n",
            "The current learning rate: 0.00033\n",
            "Epoch 12000: train loss 2.9250, val loss 2.9292\n",
            "The current learning rate: 0.00035\n",
            "Epoch 12500: train loss 2.8825, val loss 2.8847\n",
            "The current learning rate: 0.00036\n",
            "Epoch 13000: train loss 2.8308, val loss 2.8264\n",
            "The current learning rate: 0.00038\n",
            "Epoch 13500: train loss 2.7915, val loss 2.7893\n",
            "The current learning rate: 0.00040\n",
            "Epoch 14000: train loss 2.7407, val loss 2.7473\n",
            "The current learning rate: 0.00041\n",
            "Epoch 14500: train loss 2.6970, val loss 2.7039\n",
            "The current learning rate: 0.00042\n",
            "Epoch 15000: train loss 2.6630, val loss 2.6706\n",
            "The current learning rate: 0.00044\n",
            "Epoch 15500: train loss 2.6332, val loss 2.6300\n",
            "The current learning rate: 0.00045\n",
            "Epoch 16000: train loss 2.5869, val loss 2.5896\n",
            "The current learning rate: 0.00046\n",
            "Epoch 16500: train loss 2.5591, val loss 2.5615\n",
            "The current learning rate: 0.00047\n",
            "Epoch 17000: train loss 2.5194, val loss 2.5265\n",
            "The current learning rate: 0.00048\n",
            "Epoch 17500: train loss 2.4944, val loss 2.5034\n",
            "The current learning rate: 0.00048\n",
            "Epoch 18000: train loss 2.4572, val loss 2.4644\n",
            "The current learning rate: 0.00049\n",
            "Epoch 18500: train loss 2.4335, val loss 2.4413\n",
            "The current learning rate: 0.00049\n",
            "Epoch 19000: train loss 2.4041, val loss 2.4085\n",
            "The current learning rate: 0.00050\n",
            "Epoch 19500: train loss 2.3919, val loss 2.3918\n",
            "The current learning rate: 0.00050\n"
          ]
        }
      ],
      "source": [
        "best_val_loss = float('inf')\n",
        "best_model_params_path = \"best_model_params.pt\"\n",
        "train_loss_list, validation_loss_list = [], []\n",
        "\n",
        "# Ensure model is on the correct device\n",
        "model = model.to(device)\n",
        "\n",
        "# In your training loop\n",
        "for epoch in tqdm(range(max_iters)):\n",
        "    if epoch % eval_iters == 0 and epoch != 0:\n",
        "        # Ensure estimate_loss uses the correct device\n",
        "        losses = estimate_loss(model)\n",
        "        print(f\"Epoch {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "        print(f\"The current learning rate: {optimizer.param_groups[0]['lr']:.5f}\")\n",
        "        train_loss_list += [losses['train']]\n",
        "        validation_loss_list += [losses['val']]\n",
        "\n",
        "        if losses['val'] < best_val_loss:\n",
        "            best_val_loss = losses['val']\n",
        "            torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    # Ensure X and y are on the correct device\n",
        "    X, y = get_batch(\"train\")\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    with ctx:\n",
        "        logits, loss = model(X, y)\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "    if ((epoch + 1) % gradient_accumulation_steps == 0) or (epoch + 1 == max_iters):\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdzhSo_7TcgI"
      },
      "source": [
        "## Step 9: Plot the SLM Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "KSWpvAnakjK6",
        "outputId": "081faa0b-d6f6-4d37-b819-8ebb6fa9c034"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGwCAYAAACHJU4LAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWB9JREFUeJzt3Xd0FGXDBfC7m2Q3vXfSIZ0kJJQIqLTQRKQpCqiggFLsYuFVqq+ioFhAQSxgoYhIAAHphN5JCCWkEZKQQiC9t32+P/jYl5UAISSZ3eT+zplzsjvPztzZQfee2ZkdmRBCgIiIiEgLyaUOQERERHQnLCpERESktVhUiIiISGuxqBAREZHWYlEhIiIircWiQkRERFqLRYWIiIi0lr7UAR6ESqVCZmYmzMzMIJPJpI5DRERE9SCEQHFxMZydnSGX3/2YiU4XlczMTLi6ukodg4iIiBogPT0dLi4udx2j00XFzMwMwI0NNTc3lzgNERER1UdRURFcXV3Vn+N3o9NF5ebXPebm5iwqREREOqY+p23wZFoiIiLSWiwqREREpLVYVIiIiEhr6fQ5KkRE1Dhqa2tRXV0tdQxqIQwMDKCnp9coy2JRISJqxYQQyM7ORkFBgdRRqIWxtLSEo6PjA//OGYsKEVErdrOk2Nvbw9jYmD+eSQ9MCIGysjLk5OQAAJycnB5oeSwqREStVG1trbqk2NjYSB2HWhAjIyMAQE5ODuzt7R/oayCeTEtE1ErdPCfF2NhY4iTUEt38d/Wg5z6xqBARtXL8uoeaQmP9u2JRISIiIq3FokJERERai0WFiIhaNQ8PD3z11VeNsqyoqCjIZDJe7t2IeNXPnWRkoLa4CHp+/lInISKif+nZsyc6dOjQKAXjxIkTMDExefBQ1CR4RKUOZz6YALi4IGbC41JHISKiBhBCoKampl5j7ezseOWTFmNRqUNxe28AgOeZVEClkjgNEVHzEEKgtKpUkkkIUe+c48aNw759+/D1119DJpNBJpNhxYoVkMlk+Oeff9CxY0colUocPHgQycnJGDJkCBwcHGBqaorOnTtj165dGsv791c/MpkMP/74I4YNGwZjY2N4e3tj06ZNDX5f//rrLwQGBkKpVMLDwwNffPGFxvzvvvsO3t7eMDQ0hIODA5588kn1vHXr1iEoKAhGRkawsbFBREQESktLG5xFF/Grnzq0H/QCSg3eh3VJLXKO74X9Q32kjkRE1OTKqstgOs9UknWXTC+BiaJ+X798/fXXSEhIQPv27TF37lwAwPnz5wEA77//Pj7//HN4eXnBysoK6enpeOyxx/Dxxx9DqVTi119/xeDBgxEfHw83N7c7rmPOnDmYP38+FixYgEWLFmHMmDFITU2FtbX1fW3XqVOnMHLkSMyePRtPP/00Dh8+jClTpsDGxgbjxo3DyZMn8dprr+G3335Dt27dkJeXhwMHDgAAsrKyMGrUKMyfPx/Dhg1DcXExDhw4cF+lriVgUamDpbk9jnibo+uFIqRF/sKiQkSkRSwsLKBQKGBsbAxHR0cAwMWLFwEAc+fORd++fdVjra2tERISon780UcfITIyEps2bcIrr7xyx3WMGzcOo0aNAgB88skn+Oabb3D8+HEMGDDgvrIuXLgQffr0wYwZMwAAPj4+uHDhAhYsWIBx48YhLS0NJiYmePzxx2FmZgZ3d3eEhoYCuFFUampqMHz4cLi7uwMAgoKC7mv9LQGLyh3kP9QBuLAf8n37pY5CRNQsjA2MUTK9RLJ1N4ZOnTppPC4pKcHs2bOxZcsW9Qd/eXk50tLS7rqc4OBg9d8mJiYwNzdX37vmfsTFxWHIkCEaz3Xv3h1fffUVamtr0bdvX7i7u8PLywsDBgzAgAED1F85hYSEoE+fPggKCkL//v3Rr18/PPnkk7CysrrvHLqM56jcgeXAoQAAr7PpPE+FiFoFmUwGE4WJJFNj/Yrpv6/emTZtGiIjI/HJJ5/gwIEDiImJQVBQEKqqqu66HAMDg9veG1UTfBaYmZnh9OnTWL16NZycnDBz5kyEhISgoKAAenp62LlzJ/755x8EBARg0aJF8PX1RUpKSqPn0GYsKncQNHAcipSAZZkKmQf/kToOERHdQqFQoLa29p7jDh06hHHjxmHYsGEICgqCo6MjLl++3PQB/5+/vz8OHTp0WyYfHx/1jfr09fURERGB+fPnIzY2FpcvX8aePXsA3ChI3bt3x5w5cxAdHQ2FQoHIyMhmy68N+NXPHZiZWOGQjyW6ny3AlY2/w/nRQVJHIiKi/+fh4YFjx47h8uXLMDU1vePRDm9vb6xfvx6DBw+GTCbDjBkzmuTIyJ28/fbb6Ny5Mz766CM8/fTTOHLkCBYvXozvvvsOALB582ZcunQJjz76KKysrLB161aoVCr4+vri2LFj2L17N/r16wd7e3scO3YM165dg79/6/p9Lx5RuYvCrmEAAIP9ByVOQkREt5o2bRr09PQQEBAAOzu7O55zsnDhQlhZWaFbt24YPHgw+vfvj7CwsGbLGRYWhrVr12LNmjVo3749Zs6ciblz52LcuHEAAEtLS6xfvx69e/eGv78/li5ditWrVyMwMBDm5ubYv38/HnvsMfj4+ODDDz/EF198gYEDBzZbfm0gEzp8nVNRUREsLCxQWFgIc3PzRl/+sQ3fInzYKygylMGsqBKyf31nSUSkyyoqKpCSkgJPT08YGhpKHYdamLv9+7qfz28eUbmLoAHPo8AQMK8QyNi3Weo4RERErQ6Lyl0YG5rhvN+NH/fJ2PS7xGmIiEhqkyZNgqmpaZ3TpEmTpI7XIvFk2nso7toJiNkB5YEjUkchIiKJzZ07F9OmTatzXlOcgkAsKvdk+/hTwJId8L6QDVFVBZlCIXUkIiKSiL29Pezt7aWO0arwq597aB8xGrlGgEmVQOruv6SOQ0RE1KqwqNyDocIYFwLsAABX/14jcRoiIqLWhUWlHkq7dwEAGB08KnESIiKi1oVFpR4cHn8aANDuYg5UFeUSpyEiImo9WFTqIbDXSFwzAYyrgZTtf0gdh4iIqNVgUakHhb4ScYEOAIBrW9ZKnIaIiB6Uh4cHvvrqK/VjmUyGDRs23HH85cuXIZPJEBMT80Drbazl3I97bZu24+XJ9VT+8EPA8Y0wOXRC6ihERNTIsrKyYGVl1ajLHDduHAoKCjRKgqurK7KysmBra9uo62rJJD2iUlxcjDfeeAPu7u4wMjJCt27dcOKEdhYBx8GjAADeCdehKi+TOA0RETUmR0dHKJXKJl+Pnp4eHB0doa/P4wT1JWlRmTBhAnbu3InffvsNZ8+eRb9+/RAREYGMjAwpY9Up8JHhyDaTwbAGSN7Cn9MnohZICKC0VJrpPu6Pu2zZMjg7O0OlUmk8P2TIELz44otITk7GkCFD4ODgAFNTU3Tu3Bm7du266zL//fXI8ePHERoaCkNDQ3Tq1AnR0dEa42trazF+/Hh4enrCyMgIvr6++Prrr9XzZ8+ejV9++QUbN26ETCaDTCZDVFRUnV/97Nu3D126dIFSqYSTkxPef/991NTUqOf37NkTr732Gt59911YW1vD0dERs2fPrvf79W9nz55F7969YWRkBBsbG7z00ksoKSlRz4+KikKXLl1gYmICS0tLdO/eHampqQCAM2fOoFevXjAzM4O5uTk6duyIkydPNjhLvQiJlJWVCT09PbF582aN58PCwsQHH3xQ52sqKipEYWGhekpPTxcARGFhYXNEFnu7OgsBiMPjIpplfURETam8vFxcuHBBlJeX33iipESIG5Wh+aeSknrnzsvLEwqFQuzatUv9XG5urvq5mJgYsXTpUnH27FmRkJAgPvzwQ2FoaChSU1PV493d3cWXX36pfgxAREZGCiGEKC4uFnZ2dmL06NHi3Llz4u+//xZeXl4CgIiOjhZCCFFVVSVmzpwpTpw4IS5duiR+//13YWxsLP744w/1MkaOHCkGDBggsrKyRFZWlqisrBQpKSkay7ly5YowNjYWU6ZMEXFxcSIyMlLY2tqKWbNmqbP16NFDmJubi9mzZ4uEhATxyy+/CJlMJnbs2FGv9+vWbSspKRFOTk5i+PDh4uzZs2L37t3C09NTjB07VgghRHV1tbCwsBDTpk0TSUlJ4sKFC2LFihXq9y4wMFA8++yzIi4uTiQkJIi1a9eKmJiYOtd727+vWxQWFtb781uyolJUVCQAaPxDE0KI7t27ix49etT5mlmzZgkAt03NVVS2v/ekEIA452vVLOsjImpKulpUhBBiyJAh4sUXX1Q//v7774Wzs7Oora2tc3xgYKBYtGiR+vHdisr3338vbGxsND5glyxZolEw6jJ16lQxYsQI9eOxY8eKIUOGaIz5d1H5z3/+I3x9fYVKpVKP+fbbb4Wpqal6W3r06CEefvhhjeV07txZvPfee3fMcqtbt23ZsmXCyspKlNzyfm/ZskXI5XKRnZ0tcnNzBQARFRVV57LMzMzEihUr6rXexioqkn31Y2Zmhq5du+Kjjz5CZmYmamtr8fvvv+PIkSPIysqq8zXTp09HYWGhekpPT2/WzG2eeBYA4J2Uj5qSomZdNxFRkzM2BkpKpJmMje8r6pgxY/DXX3+hsrISALBy5Uo888wzkMvlKCkpwbRp0+Dv7w9LS0uYmpoiLi4OaWlp9Vp2XFwcgoODYWhoqH6ua9eut4379ttv0bFjR9jZ2cHU1BTLli2r9zpuXVfXrl0hk8nUz3Xv3h0lJSW4cuWK+rng4GCN1zk5OSEnJ+e+1nVzfSEhITAxMdFYn0qlQnx8PKytrTFu3Dj0798fgwcPxtdff63xmfzWW29hwoQJiIiIwKeffork5OT7znC/JD1H5bfffoMQAm3atIFSqcQ333yDUaNGQS6vO5ZSqYS5ubnG1Jz8wgchw0IGRS2Q9PcvzbpuIqImJ5MBJibSTLd8UNfH4MGDIYTAli1bkJ6ejgMHDmDMmDEAgGnTpiEyMhKffPIJDhw4gJiYGAQFBaGqqqrR3qo1a9Zg2rRpGD9+PHbs2IGYmBi88MILjbqOWxkYGGg8lslkt52j01iWL1+OI0eOoFu3bvjjjz/g4+ODo0dv/DL77Nmzcf78eQwaNAh79uxBQEAAIiMjmyTHTZIWlbZt22Lfvn0oKSlBeno6jh8/jurqanh5eUkZ64709PSRENwGAJC/db3EaYiIWi9DQ0MMHz4cK1euxOrVq+Hr64uwsDAAwKFDhzBu3DgMGzYMQUFBcHR0xOXLl+u9bH9/f8TGxqKiokL93M0P6psOHTqEbt26YcqUKQgNDUW7du1uO7qgUChQW1t7z3UdOXIE4paTiQ8dOgQzMzO4uLjUO3N9+fv748yZMygtLdVYn1wuh6+vr/q50NBQTJ8+HYcPH0b79u2xatUq9TwfHx+8+eab2LFjB4YPH47ly5c3es5bacUPvpmYmMDJyQn5+fnYvn07hgwZInWkO6rp8QgAwOJo9D1GEhFRUxozZgy2bNmCn3/+WX00BQC8vb2xfv16xMTE4MyZMxg9evR9HX0YPXo0ZDIZJk6ciAsXLmDr1q34/PPPNcZ4e3vj5MmT2L59OxISEjBjxozbfl7Dw8MDsbGxiI+Px/Xr11FdXX3buqZMmYL09HS8+uqruHjxIjZu3IhZs2bhrbfeuuO3Cw9izJgxMDQ0xNixY3Hu3Dns3bsXr776Kp577jk4ODggJSUF06dPx5EjR5CamoodO3YgMTER/v7+KC8vxyuvvIKoqCikpqbi0KFDOHHiBPz9/Rs9560kLSrbt2/Htm3bkJKSgp07d6JXr17w8/PDCy+8IGWsu3J94nkAgM+lQlQV5Eqchoio9erduzesra0RHx+P0aNHq59fuHAhrKys0K1bNwwePBj9+/dXH22pD1NTU/z99984e/YsQkND8cEHH+Czzz7TGPPyyy9j+PDhePrppxEeHo7c3FxMmTJFY8zEiRPh6+uLTp06wc7ODocOHbptXW3atMHWrVtx/PhxhISEYNKkSRg/fjw+/PDD+3w36sfY2Bjbt29HXl4eOnfujCeffBJ9+vTB4sWL1fMvXryIESNGwMfHBy+99BKmTp2Kl19+GXp6esjNzcXzzz8PHx8fjBw5EgMHDsScOXOaJOtNMnHr8aZmtnbtWkyfPh1XrlyBtbU1RowYgY8//hgWFhb1en1RUREsLCxQWFjYbOerqIQK6TYGcM9X4fyKBQgcO61Z1ktE1NgqKiqQkpICT09PjRNHiRrD3f593c/nt6RHVEaOHInk5GRUVlYiKysLixcvrndJkYpcJkdyiBsAoHDbRonTEBERtWxacY6KrlH1fBQAYH3sjMRJiIioNVu5ciVMTU3rnAIDA6WO1yh4s4EGcB86Dpj9K7wvF6Mi9yoMbRykjkRERK3QE088gfDw8Drn/fuSZl3FotIA7YJ74pKtHryu1+JC5E8ImvAfqSMREVErZGZmBjMzM6ljNCl+9dMAMpkMlzt4AACKt2+SNgwR0QNqqh8Oo9atsf5d8YhKQ/XsBexKhu3xc1InISJqEIVCAblcjszMTNjZ2UGhUGj8lDtRQwghUFVVhWvXrkEul0OhUDzQ8iS9PPlBSXF58k0pFw7DM7A7VDKgIisdxg6N/wuCRERNraqqCllZWSgrK5M6CrUwxsbGcHJyqrOo3M/nN4+oNJCHf1ck2uvDO6cGiet/RMjk2VJHIiK6bwqFAm5ubqipqbnnz70T1Zeenh709fUb5Qgdi0oDyWQypIV6wXt7Akp3bAFYVIhIR8lkMhgYGLSYq0SoZeHJtA9A3icCAOBw4rzESYiIiFomFpUH0G7YeABA24xylFxJkTgNERFRy8Oi8gBc24Uh3unGodLE9T9InIaIiKjlYVF5QOlh3gCA8p3/SJyEiIio5WFReUAGffoCAJxOXpQ4CRERUcvDovKAvIdNgAqAZ3YFClNYVoiIiBoTi8oDcvZoj4suSgBA0vofJU5DRETUsrCoNILMjj4AgKpd2yROQkRE1LKwqDQCZb/HAACuJxIA3b0jARERkdZhUWkEAU9ORrUccMmtRk7sUanjEBERtRgsKo3Axt4dZ71MAQCX1i2TOA0REVHLwaLSSHK7dQAA6O3eI20QIiKiFoRFpZFYDh4JAGgXkw5RUyNxGiIiopaBRaWRBD3+AoqUgFW5wKU9f0kdh4iIqEVgUWkkhoamOB9oBwDIjvxN4jREREQtA4tKIyrt0Q0AYHqAV/4QERE1BhaVRtRm2FgAgN/FXFQVF0gbhoiIqAVgUWlEvt2fQKaFHMpaIH7DT1LHISIi0nksKo1ILtdDQpg7AKBwC0+oJSIielAsKo2tTwQAwO7IGYmDEBER6T4WlUbW7qmXAAC+aWUoTE+SOA0REZFuY1FpZC4+nRDvrAAAxP+5ROI0REREuo1FpQlkdPEHAFRv/0fiJERERLqNRaUJGA0YDABwP5kICCFxGiIiIt3FotIEAkZMQpUe4JJXg4zo/VLHISIi0lksKk3AwrYNzrc1AwBcXvejxGmIiIh0F4tKE8nv3hEAoL8nStogREREOoxFpYnYPPEMAMAnNgOqmmqJ0xAREekmSYtKbW0tZsyYAU9PTxgZGaFt27b46KOPIFrACagBA59HoRKwKhdI2LlG6jhEREQ6SdKi8tlnn2HJkiVYvHgx4uLi8Nlnn2H+/PlYtGiRlLEahYHSCHHtHQAAVzeukjgNERGRbtKXcuWHDx/GkCFDMGjQIACAh4cHVq9ejePHj0sZq9FU9HoEOLUO5vuPSR2FiIhIJ0l6RKVbt27YvXs3EhISAABnzpzBwYMHMXDgwDrHV1ZWoqioSGPSZi7DxwEAAhLyUV6YK20YIiIiHSRpUXn//ffxzDPPwM/PDwYGBggNDcUbb7yBMWPG1Dl+3rx5sLCwUE+urq7NnPj+tA0fiEwLOZS1QNyGH6SOQ0REpHMkLSpr167FypUrsWrVKpw+fRq//PILPv/8c/zyyy91jp8+fToKCwvVU3p6ejMnvj8yuRxJHb0AAMWb10uchoiISPdIeo7KO++8oz6qAgBBQUFITU3FvHnzMHbs2NvGK5VKKJXK5o75QPT69gP2JMHh2DmpoxAREekcSY+olJWVQS7XjKCnpweVSiVRosbnPXISAMAvvRzXL8dJnIaIiEi3SFpUBg8ejI8//hhbtmzB5cuXERkZiYULF2LYsGFSxmpU9l5BiG9jCABI+HOpxGmIiIh0i6RFZdGiRXjyyScxZcoU+Pv7Y9q0aXj55Zfx0UcfSRmr0WWFBwIAandskzgJERGRbpEJHf4Z2KKiIlhYWKCwsBDm5uZSx7mjEz/OReeJs3DFSg9trldBJuedC4iIqPW6n89vfmI2g4ARk1ClB7jk1yL15G6p4xAREekMFpVmYGJljwvtLAAAqX/9JHEaIiIi3cGi0kwKHu4EAFBE7Zc4CRERke5gUWkmdkNGAwD8Y7NQU10pcRoiIiLdwKLSTPz6j0GhIWBZAcRt+13qOERERDqBRaWZ6CmUuBjkBAC4tmm1xGmIiIh0A4tKM6rq1QMAYHnwpMRJiIiIdAOLSjNyHzEeABCYWIiS/KsSpyEiItJ+LCrNyK1zH2Ra6kFZC5xf/73UcYiIiLQei0pzkslwqVNbAEDp1o0ShyEiItJ+LCrNTL/fAACA87HzEichIiLSfiwqzcznqckAAL+MSmRfipU4DRERkXZjUWlm1h5+iHcxAgAk/LFE4jRERETajUVFAjldg2/8se0faYMQERFpORYVCVg9+SwAIOBUGqqrKiROQ0REpL1YVCTgP2QCCg1lsC0VOLvlZ6njEBERaS0WFQnoKQ0RF+YGAMj/8zeJ0xAREWkvFhWpDHoMAOB8IEbaHERERFqMRUUifs++CZUM8L9SgbRzh6WOQ0REpJVYVCRi6eaNOC8zAEDyykUSpyEiItJOLCoSyuvVDQBguGO3xEmIiIi0E4uKhJxHTQQABJ+9hpKi6xKnISIi0j4sKhLy6jkMWRZ6MKkGzv7Br3+IiIj+jUVFQjK5HJce8gUAlG9cJ3EaIiIi7cOiIjGjYU8BANodiYdQqSROQ0REpF1YVCQW8MyrqNAH3PJqcfFApNRxiIiItAqLisQMLWxwPtAeAJCxZpnEaYiIiLQLi4oWqOjXGwBgveeIxEmIiIi0C4uKFmj77GsAgODEYly7kiBxGiIiIu3BoqIFHIO7ItnJEPoCuPD7l1LHISIi0hosKloi69FQAIBs61aJkxAREWkPFhUtYf3k8wCAwFPpqK6qkDgNERGRdmBR0RJ+Q15EgZEMNmUCsZt+kDoOERGRVmBR0RJyAwXiO7oDAPL/+l3iNERERNqBRUWbDHocANDmwBmJgxAREWkHFhUt4v/sm1DJAP+MSlw+e0DqOERERJKTtKh4eHhAJpPdNk2dOlXKWJIxd/FCXFtzAEDy77ybMhERkaRF5cSJE8jKylJPO3fuBAA89dRTUsaSVH6f7gAA4517JU5CREQkPUmLip2dHRwdHdXT5s2b0bZtW/To0UPKWJJyeeZlAEDIuesoLsiROA0REZG0tOYclaqqKvz+++948cUXIZPJ6hxTWVmJoqIijamlcX90MLIs9WFcDcT+8Y3UcYiIiCSlNUVlw4YNKCgowLhx4+44Zt68ebCwsFBPrq6uzRewmcjkclzq5gcAqNz4l8RpiIiIpKU1ReWnn37CwIED4ezsfMcx06dPR2FhoXpKT09vxoTNx2ToSACA99EEqFS1EqchIiKSjlYUldTUVOzatQsTJky46zilUglzc3ONqSUKeOZVlOsDrvkqXNi3Tuo4REREktGKorJ8+XLY29tj0KBBUkfRCgozS8S1dwAAZK/5UeI0RERE0pG8qKhUKixfvhxjx46Fvr6+1HG0RmX/CACA9d6jEichIiKSjuRFZdeuXUhLS8OLL74odRSt0u651wEAwUkluJoWJ3EaIiIiaUheVPr16wchBHx8fKSOolXsAjsj2dkQ+gKIW/mV1HGIiIgkIXlRoTvL6tERACDb+o/ESYiIiKTBoqLFbJ8aCwAIOpWOysoyidMQERE1PxYVLebz+FjkG8lgXQ7EblwmdRwiIqJmx6KixeQGCsR38gQAFKxfKXEaIiKi5seiouX0Hh8MAHDdHwshhMRpiIiImheLipbze/YN1MoAv6wqXDoTJXUcIiKiZsWiouXMnD0Q520JAEj+6XNpwxARETUzFhUdUDLsxq0FnDfu4dc/RETUqrCo6IDAV+aiWg60T6/Ahf1/SR2HiIio2bCo6AAzFy/EhjoDADKXzJc4DRERUfNhUdEVzz4LAPDbcQo1NVUShyEiImoeLCo6InjCByhSyuCar8Lptd9IHYeIiKhZsKjoCANTc5x71A8AULrie4nTEBERNQ8WFR1iOWEqACD0QBJKiq5LnIaIiKjpsajoEP8Rk5BlqQfLCuD0jx9JHYeIiKjJsajoEJmeHpIHPgQA0F+1RuI0RERETY9FRce4TpkOAOgUk4Oc1DiJ0xARETUtFhUd4/7wIMS7GkNRC5z7dpbUcYiIiJoUi4oOujasHwDAZv1WiZMQERE1LRYVHeT/6lzUyoCQ5FIkn9wpdRwiIqImw6Kig2zaBeFMoC0A4PLi/0qchoiIqOmwqOioqtEjAQBeWw9DqFQSpyEiImoaLCo6KnjSLJQaAJ7XahC7+Sep4xARETUJFhUdZWxlj9iungCAvB947x8iImqZWFR0mOG4iQCAoL3nUVVRKnEaIiKixseiosOCx7yFHDM5bEsFTi+fJ3UcIiKiRseiosP0FEpcjOgAAKj9/RdpwxARETUBFhUd5/Dy2wCAsONXUHA1VeI0REREjYtFRcf59H0GyY5KGNUAsUtmSx2HiIioUbGo6DiZXI4rg3sAAEzXbpA2DBERUSNjUWkB2r0yEwDQIa4AGReOSZyGiIio8bCotABtgrsjxtcCcgAJi+ZIHYeIiKjRNKiopKen48qVK+rHx48fxxtvvIFly5Y1WjC6P8VPPgEAaLNpD39Sn4iIWowGFZXRo0dj7969AIDs7Gz07dsXx48fxwcffIC5c+c2akCqn+BXPkKlHuCTWYmEveukjkNERNQoGlRUzp07hy5dugAA1q5di/bt2+Pw4cNYuXIlVqxY0Zj5qJ4sHN1xulMbAED2kgUSpyEiImocDSoq1dXVUCqVAIBdu3bhiSdufO3g5+eHrKysxktH90X23HMAAN+dp1FbXSVxGiIiogfXoKISGBiIpUuX4sCBA9i5cycGDBgAAMjMzISNjU2jBqT6C33hP8gzlsGxSIXY1V9JHYeIiOiBNaiofPbZZ/j+++/Rs2dPjBo1CiEhIQCATZs2qb8Sqq+MjAw8++yzsLGxgZGREYKCgnDy5MmGxGr1lMZmONvDHwBQtoInNhMRke7Tb8iLevbsievXr6OoqAhWVlbq51966SUYGxvXezn5+fno3r07evXqhX/++Qd2dnZITEzUWCbdH8sJrwD/TEHIoWSUFVyDsaWd1JGIiIgaTCaEEPf7ovLycggh1KUkNTUVkZGR8Pf3R//+/eu9nPfffx+HDh3CgQMH6jW+srISlZWV6sdFRUVwdXVFYWEhzM3N728jWiiVqhZpDobwuF6DA9NG4pEFf0gdiYiISENRUREsLCzq9fndoK9+hgwZgl9//RUAUFBQgPDwcHzxxRcYOnQolixZUu/lbNq0CZ06dcJTTz0Fe3t7hIaG4ocffrjj+Hnz5sHCwkI9ubq6NiR+iyaX6+Hyi8MBAF4//oXq8lKJExERETVcg4rK6dOn8cgjjwAA1q1bBwcHB6SmpuLXX3/FN998U+/lXLp0CUuWLIG3tze2b9+OyZMn47XXXsMvv/xS5/jp06ejsLBQPaWnpzckfosX/uFS5JjK0aagFscXvCl1HCIiogZrUFEpKyuDmZkZAGDHjh0YPnw45HI5HnroIaSmptZ7OSqVCmFhYfjkk08QGhqKl156CRMnTsTSpUvrHK9UKmFubq4x0e2MzKxw7rkbX8E5ffcLVDXVEiciIiJqmAYVlXbt2mHDhg1IT0/H9u3b0a9fPwBATk7OfZUHJycnBAQEaDzn7++PtLS0hsSiW3ScswwFhoDX1SqcWPwfqeMQERE1SIOKysyZMzFt2jR4eHigS5cu6Nq1K4AbR1dCQ0PrvZzu3bsjPj5e47mEhAS4u7s3JBbdwsLOBaefevjG3wu/5f1/iIhIJzXoqh/gxj1+srKyEBISArn8Rt85fvw4zM3N4efnV69lnDhxAt26dcOcOXMwcuRIHD9+HBMnTsSyZcswZsyYe77+fs4abo1y0xOgbOcL0yrg1E//RccXP5A6EhER0X19fje4qNx08y7KLi4uDXr95s2bMX36dCQmJsLT0xNvvfUWJk6cWK/Xsqjc294RHdFr/Wmc8bFASHyB1HGIiIia/vJklUqFuXPnwsLCAu7u7nB3d4elpSU++ugjqO7zK4bHH38cZ8+eRUVFBeLi4updUqh+fD9eiko9ICShEGfXfSd1HCIiovvSoKLywQcfYPHixfj0008RHR2N6OhofPLJJ1i0aBFmzJjR2BnpATj7dcbRiBtfxVX+d7a0YYiIiO5Tg776cXZ2xtKlS9V3Tb5p48aNmDJlCjIyMhot4N3wq5/6uXxqN1w7R0BPAPE7VsO37zNSRyIiolasyb/6ycvLq/OEWT8/P+Tl5TVkkdSEPDr2wdHuN66kypv1jsRpiIiI6q9BRSUkJASLFy++7fnFixcjODj4gUNR47P76AsAQPiRK0g5uk3iNERERPXToLsnz58/H4MGDcKuXbvUv6Fy5MgRpKenY+vWrY0akBqHT88RONbRAeGnriLjw9fguStB6khERET31KAjKj169EBCQgKGDRuGgoICFBQUYPjw4Th//jx+++23xs5IjcRk5n8BAOF7E5Fx7ojEaYiIiO7tgX9H5VZnzpxBWFgYamtrG2uRd8WTae/f6QArhMUVYN8TIeixMUbqOERE1Ao1+cm0pMOm37jvT5etZ3At5bzEYYiIiO6ORaWVCR3zNs55msCoBjj/AX9cj4iItBuLSisjk8tR+vZrAIDQ9UdQmJ0qcSIiIqI7u6+rfoYPH37X+QUFBQ+ShZpJ50lzkfjxQnhnVSJq5kT0XLZD6khERER1uq8jKhYWFned3N3d8fzzzzdVVmokcj195Lz6IgCg/apdKCu8LnEiIiKiujXqVT/NjVf9NFxNVQUync3glluDqDeHoefC9VJHIiKiVoJX/dA96SsMkfrS0wAAn583oaq8ROJEREREt2NRacW6/OdbZJvL4VxYi6Ofvip1HCIiotuwqLRiSlMLxD8/CADgumQlqivLJU5ERESkiUWlles4ZxlyjWXwvFaNQx88J3UcIiIiDSwqrZyptSMuvPoMACDku/W4nhYvcSIiIqL/YVEhdPtoBRLaGMKqXOD8pLv/Vg4REVFzYlEh6BkoUPHFfADAw9su4OLuPyROREREdAOLCgEAgp9+FUe6ukJPAOVTX4ZQqaSORERExKJC/+P+/R8o1wdC4wtx+Mu3pY5DRETEokL/4xzUFcfH9AQAuH+8iD+tT0REkmNRIQ1dvl6HDEs9uOTX4thrI6SOQ0RErRyLCmkwsrBB+ozXAAAPrdqPK7GHJE5EREStGYsK3Sb8jc8R42sBoxog7eVnpI5DREStGIsK3UYml8N4yY+olQHdjl5B9OovpY5EREStFIsK1cmn15M4NDAQAGD8zn9QU1UhcSIiImqNWFTojtovjUS+kQy+GRU4NGOc1HGIiKgVYlGhO7J29Ubs1BtX/gQtXov8jGSJExERUWvDokJ31f3j35DorIR1mUDspGFSxyEiolaGRYXuSl9hiJL5HwMAum89i4So9RInIiKi1oRFhe4pdMzbONrFGfoqoGTqBN4HiIiImg2LCtVLm2VrUK4PhF3Ix7HF70sdh4iIWgkWFaoX15BHcPSZhwEAbeZ8ifKiPIkTERFRa8CiQvXW5Zu/kGmpB9e8Ghx7a6TUcYiIqBWQtKjMnj0bMplMY/Lz85MyEt2FiZU9UqZPBgA89MtuxO9eK3EiIiJq6SQ/ohIYGIisrCz1dPDgQakj0V10m/Y1joU5wLAGUIx+FsW5WVJHIiKiFkzyoqKvrw9HR0f1ZGtrK3UkuguZXA7vDQeQaakHz5xqnBnejVcBERFRk5G8qCQmJsLZ2RleXl4YM2YM0tLS7ji2srISRUVFGhM1P2tXb1z/8RvUyIGH91/GwY8mSh2JiIhaKEmLSnh4OFasWIFt27ZhyZIlSElJwSOPPILi4uI6x8+bNw8WFhbqydXVtZkT003BI6bg4Ph+AICwj39G0sFNEiciIqKWSCaEEFKHuKmgoADu7u5YuHAhxo8ff9v8yspKVFZWqh8XFRXB1dUVhYWFMDc3b86oBEBVW4PoDo7oeC4XCc5KuMRlwNjcRupYRESk5YqKimBhYVGvz2/Jv/q5laWlJXx8fJCUlFTnfKVSCXNzc42JpCPX04fbxijkmMnhk1mJEyO7Sx2JiIhaGK0qKiUlJUhOToaTk5PUUaie7LzaI/O7+VAB6LE9Hgc/e0XqSERE1IJIWlSmTZuGffv24fLlyzh8+DCGDRsGPT09jBo1SspYdJ86PPs2Djz3CAAgeNa3SDmxU+JERETUUkhaVK5cuYJRo0bB19cXI0eOhI2NDY4ePQo7OzspY1EDPPzjTpzxsYB5JVA+YggqSguljkRERC2AVp1Me7/u52QcanrZF0/CoGMX2JQJ7B0chF6bYqWOREREWkhnT6Yl3ebo1wmXv5oNAOj191kcXvSutIGIiEjnsahQo+o4cSb2P9UFABDw7gKkxR6QOBEREekyFhVqdN1+3YsLnqawrAAKhg1EVUWp1JGIiEhHsahQo9M3NIZl5DYUGsoQfKkUB8b2lDoSERHpKBYVahLOId2R+Nl7AIA+a0/iyLKZEiciIiJdxKJCTabTa/NwcHAIAKD9qx/hyOoFEiciIiJdw6JCTarL6v2IaW8Lsyqg/bh3EfXbf6WOREREOoRFhZqUwsQcgYeTcDbYAWZVQMcJM7BtxYdSxyIiIh3BokJNzsDMAgGHEnEhxBlmVUD3lz9G5A9vSx2LiIh0AIsKNQs9UzP4HYpHfAdXmFUBEa8sxKrvpkgdi4iItByLCjUbuYkpfA7GISnME2ZVwBNvLMFP37wAHb6LAxERNTEWFWpWMhMTtDtwDimd2sG0Gnh62gosXvgMywoREdWJRYWan7ExPPfHIq2LL0yrgRemr8WC+UNRq6qVOhkREWkZFhWShpER3KKikREeANNqYMqMTfh43kDUqGqkTkZERFqERYWkY2SENntPIvuhIJhWA2/N2YmZH/VGZU2l1MmIiEhLsKiQtIyM4LjnGK516wDTauA/Hx/A9DmPoKy6TOpkRESkBVhUSHpGRrDbdRi53cNgWg3M/ewE3p3eCTmlOVInIyIiibGokHYwMoLNzoMoeLgTTKuBrxbG4afRfojLuSB1MiIikhCLCmkPIyNY7tiPwpFDoC+A6ZvykdS7A/af+VvqZEREJBEWFdIuRkawWBOJ4q/mo0pfhsHnq+HU5wls/JM3MyQiao1YVEj7yGQwe/0diH37cN3GGN65QN/RM7DuP0P5w3BERK0MiwppLWW3R2Adl4LEjp4wrgGenLcRuwb6orK0SOpoRETUTFhUSKvJ7ezhfSwRpycOBgD03Z6I5CAX5MefkTgZERE1BxYV0n56eghbtgnRP/4X+UZAQEox0DEMGX8tlzoZERE1MRYV0hmh4z/AtX3bcNZFAatSFZyeehGpb08AVCqpoxERURNhUSGd4tO5P+yi4xH5iB3kAnBf+BMyenYEcnOljkZERE2ARYV0jqOtB/rvvozFk8JQrg+0ORCDAj8PVO3eIXU0IiJqZCwqpJOMDYwx+dvjWPL1s0iwBiyvl0C/b39kvz4eqK6WOh4RETUSFhXSWXpyPbw15Tck71qLVZ0NIReA4zc/40oHL9QkJUgdj4iIGgGLCum8gaFPoV9UOr54IxwFSsDlwhVUBvkjc+nnUkcjIqIHxKJCLYKtsS3eWngEURu+whF3PZhUqOA8+R1cfKwLVIUFUscjIqIGYlGhFkMmk2HogNfhejoJvw7zQq0M8PvnBLK9nXF1D29sSESki1hUqMVxsfbAc38lYeOyt5BqKYPztXJY930C0a+NhKipkToeERHdBxYVapFkMhmGT/gC1aeOY2dnGxiogNBFf+JcByfkJsZKHY+IiOqJRYVatHZendDrSBb+nj4CJQog6Px1yDp0wP43hqGs8LrU8YiI6B5YVKjF09czwOBP1iF9zwacdzOEdZnAo19vQImLA/a+OhjF+VeljkhERHegNUXl008/hUwmwxtvvCF1FGqh/LsPQbuL1xA14zmk2ejDvkSFXos3o9zNCTunDEBBbobUEYmI6F+0oqicOHEC33//PYKDg6WOQi2c0sgUPef+CqcrhTg060Wk2xjAvkSg75LtqPJwxdZJEbiWc1nqmERE9P8kLyolJSUYM2YMfvjhB1hZWUkdh1oJA0NjdJ/9E5wzinB87iSk294oLI99vxvw8sTfE3sgOztZ6phERK2e5EVl6tSpGDRoECIiIu45trKyEkVFRRoT0YPQUxqiy4wlaJNRjNMfv4IrtgrYlQKDf9wPebt2WD++G9Iy4qSOSUTUaklaVNasWYPTp09j3rx59Ro/b948WFhYqCdXV9cmTkithVyhRNh/FqFNRjHOfvoWMuyUsC8Fhv98BErfAGx4+3GUV5ZKHZOIqNWRrKikp6fj9ddfx8qVK2FoaFiv10yfPh2FhYXqKT09vYlTUmsjUygQ9N4XcL5ShIsL3kOmnSEcSoGhC7cgwccGh9d9KXVEIqJWRSaEEFKseMOGDRg2bBj09PTUz9XW1kImk0Eul6OyslJjXl2KiopgYWGBwsJCmJubN3VkaoVEVRXOzngJnl//CrPKG/+p7OnhDr8fI+HcLlTidEREuul+Pr8lKyrFxcVITU3VeO6FF16An58f3nvvPbRv3/6ey2BRoeZSkpqECxOHosvO8wCAQiUQ/fITeHj+GugrjSROR0SkW+7n81uyr37MzMzQvn17jcnExAQ2Njb1KilEzcnUvR267DiHpC2/Ic7DBBaVQM9vNiHV0wrnV38jdTwiohZL8qt+iHRJu8eehW9SAQ58+Dyum8jQNqsSgaNfx6lunsi/GCN1PCKiFkeyr34aA7/6ISnlZiQh+uUn0HNrHPQFUK4PXBw/BCELV0JubCJ1PCIiraUTX/0Q6TqbNu0QsfkCYretwHFvYxjVAKHfb0SOqzUu/vdNiMpKqSMSEek8FhWiBxTWbyxCL+Rj05wxuGIhg2NeFfxmfIWrzua4MOdViIoKqSMSEeksFhWiRmCgr8ATM3+HLD4B615+FJlmgGNeFQJmL0aOswXOzZoMUV4udUwiIp3DokLUiNo4tMOTS/dBlnwJ66f0QoY54JBfhfZzl+KaswXOfjARoqxM6phERDqDRYWoCTjZeWL4t3ugn3wZka9E4IqFDPYF1Qj65Edcd7LAmfdfgKq0ROqYRERaj0WFqAk52Lpj2KKdUF5Kw4bX+yPNUga7ohqEfLYCeU5WiHnnOdQW8+aaRER3wqJC1AzsrF0w9KttML2ciY1vDUKqlQy2xTXo8PnvKHKywukXB6L8cpLUMYmItA6LClEzsrZwxJAvNsMi9So2vfMELlvLYVWqQtjybdBv640zEUHI3b9d6phERFqDRYVIApZmdnhi/kbYpF3H5nkv4LiXEgYqIGT3Odj0GIDEAAek//QlUFMjdVQiIkmxqBBJyMzECo+//zPCEkuwa+2n+OchW1TJAe+4HLhOeAtXncyQMP1liPx8qaMSEUmCRYVIC+jL9RHx1HsYeOQaYo9uxLrhfrhmDDhcr4DPp8tQ7mSLuGciUBV3XuqoRETNikWFSMt06vwEnvwrDiWJ57H69T447yCDcaUK/n/shn5geyQ+5I1rq37k10JE1CqwqBBpKU/nAIz6ahfapORizVcTsTPAEHIBeB9Lgt2Yibhub4q4SU+i6lKi1FGJiJoM755MpCOqa6uxbdtilH73FXpHpcH+/3/gViUD4jt5wHTqW3AdMxnQ15c2KBHRPdzP5zeLCpEOSs6Ow/ElH8Jl9WY8klilfv6ahQEynuoP73c/g4l3gIQJiYjujEWFqJWoUdVg/+6fkb94AR7enQSH0hvPq2TA+TAXKCa9Ap/n34RMoZA2KBHRLVhUiFqh7Lw0HP12OuxWRqJ7/P/u1JxvoofUvp3h+vK7sOk3BJDz1DQikhaLClErJoTAiQNrkPP1J+i84xwcbrn34TVrQ+Q/0Reek/8Dg87hgEwmXVAiarVYVIgIAFBYkotDv/wXqtUr8fDJa7Cs/N+8HGdL1D79FJxeegvw85MuJBG1OiwqRHSb+IxYHP9xDiwityLifAWMb/kZlhzvNjB+/kWYPj8BcHOTLiQRtQosKkR0RzWqGuw5sxHxKxag7bbj6JskYKD63/xrnfxhPuEVKJ8ZA1hYSBeUiFosFhUiqpe88jxEHvwRV3/9Dl0PpqLH5f/9CmSVgRzZEQ/BftI0GD42mL/PQkSNhkWFiO7buZxz2LTrO+itXoPBR/MRcP1/8/ItlMgZEgHXVz+Acaeu0oUkohaBRYWIGkwIgdOZp3B442KY/RGJQSeLYFf2v/mpbubIe2owfF6ZBRMPb+mCEpHOYlEhokYhhEB0+nGc/WUB7NdvQ++zpVDW3phXKwNig+xRMbAv2o5+BfbBD0kbloh0BosKETU6IQTOxR9A8vfz4LoxCh1TKjTmp9orkdk9GJZDn4HPiJegZ2IqUVIi0nYsKkTUpIQQuHh0MzKWfw3rqOMISi7WuHKoXB9ICHJCTd8IeI2eCqvgLvxxOSJSY1EhomaVk5GI82sXQbVlC/xOpqBNoeb/VjJslch6OARWQ0fBc/iLkJvxv1ei1oxFhYgkU1NbjTN7ViN73QrY7DuB0KQS9XktAFClByT7O6K6T0+4j3wJFg/14P2HiFoZFhUi0hoZmfE498ci1P6zBX6nUuGVp/m/nHwzfWSEB8Bk0HC4j5wAuXMbiZISUXNhUSEirVRZU4lTB9Yie/0vsNx3HJ3ji2FWpTkmzd0SpT27o82IF2DedxBgaChNWCJqMiwqRKQT0q4nIyZyCaq2/g3PE0kIzVDh1i+BKhRypIV6QW/gILg98zIMfP0ly0pEjYdFhYh0TlVtFY7HbEXqXz/BZO9BdD5fgDbFmmMyHYxx7ZGOsB42Gi5PPAuZKS+BJtJFLCpEpPPSC9JwcscKlP+9Hq5HLiA8pRqKWy6BrtAHkgKdUdW3F9yfmQSbsO68BJpIR7CoEFGLohIqnE06jOS/foBix24En86AW6HmmExrA6SH+8O43yC0Gz4BRm5e0oQlontiUSGiFq28qgzRe1cjN3IlbPefRFhCscYl0ACQ6mSM3PBgWA4cCo8hYyF3cJQmLBHdhkWFiFqVnJwUxP25BBU7tqLNqQQEZFTj37/Mku5qjqJunWA/aCTsHnsSsLGRJCsR6VBRWbJkCZYsWYLLly8DAAIDAzFz5kwMHDiwXq9nUSGifxNCIDHpGBIjf0Ltnt3wOpOK9tkqjTEqGZDpYYOK7uGwjxgK894DAFdXiRITtT46U1T+/vtv6OnpwdvbG0II/PLLL1iwYAGio6MRGBh4z9ezqBDRvVTXVuNU7DakbvwVevsPwP/cVQReu31cnq0Jijq2h3mvAbDu8zgQEgIYGDR/YKJWQGeKSl2sra2xYMECjB8//rZ5lZWVqKysVD8uKiqCq6sriwoR1VthRSGOnNyAzM2roDx2Cr7xueiQDej/6/+ElQo95Lb3gsGjvWDbZzBk3boB1tbShCZqYXSyqNTW1uLPP//E2LFjER0djYCAgNvGzJ49G3PmzLnteRYVImqovPI8HL24G2k71wFHDsPtfAa6pgtYVdQx1sUGFaFBMO3eC+bdewOhoYCJSfOHJtJxOlVUzp49i65du6KiogKmpqZYtWoVHnvssTrH8ogKETW10qpSHE07jIsHN6B8/27Yn0lCeGotfHNvH1srA3I87FDRoT1MuvWEbY8BkId0ABSKZs9NpEt0qqhUVVUhLS0NhYWFWLduHX788Ufs27evziMq/8ZzVIioqVXVVuFU5imcit2OkiNRMIo5B4+kXHTOAJxL6hivL0OWlx3KQgJh1PEh2HeLgHFoF4C/okukplNF5d8iIiLQtm1bfP/99/ccy6JCRFIorSpF7NVYJMZGofjwXhjFnINL4lV0vKKCTXndr8m2M0ZeO2fUtA+AWcducOraD4YBQYC+fvOGJ9ICOl1UevfuDTc3N6xYseKeY1lUiEhb1KhqEH/tIhJP7UDxob1QxMTCLikbvllVt92z6KZKfRmuuJijyNsNCAmGbe/BcOk1BDLeMZpaOJ0pKtOnT8fAgQPh5uaG4uJirFq1Cp999hm2b9+Ovn373vP1LCpEpO2ul11HfPxhXDu2B1Uxp2AclwTHlGvwz66FSfXt4yv0gUQvC+SG+kPRoxfcB46Cs3t7yHgfI2pBdKaojB8/Hrt370ZWVhYsLCwQHByM9957r14lBWBRISLdJITA1eIsJJ/ahbzj+6A6EwOLuBQEJObDvvT28fEOergU2AYVXcJgGfE42ocPhp2pffMHJ2okOlNUHhSLChG1JFU1lUg6tg05O9ZD7/BRuJxNhefVytvGZZkCMZ5GKPB0gsq7HYwDQmAf+jDaeYfD3sSeR19I67GoEBG1EOWZaUj9ZzVK9+6A+clYuCddh6K27rG5RkCynR6ut7FCuZcr9Hz9YdG+E9qE9YSnS3sY6PGXdkk7sKgQEbVU5eUoPbwP2VFbUBV3FnrJKbBMz4F9bh2/UHeLK+bAFRdzlHp7QBESBqfwPvDo9hj0Lflru9T8WFSIiFqbsjJUXjyP7NP7UXT2JFTxF2F0+Qrsr+TDsvQOh2AAZFsrkOfhCBHgD8uO3eEY3gd67YMAM7NmDE+tDYsKERGpqXKvI/PEHmQd3YWKM6dgmJiCNukFcC668//+8+zMUOLrAb3gDrDu9AiMQjsD/v6AUtmMyamlYlEhIqK7UgkVLl06hUuHNqPg9GHIzl+ATUo2/K6q6vzFXQColcuQ62KNCt+2UHboBOsuPWAQ3AFo2xbQ02vW/KTbWFSIiOi+1apqEZ8bj9iL+3D9+D7UnjsDi4Q0eGaUIegqYH2H02CqFHrIc7VFtZsL9Np5w8wvBKa+QZC1bQt4eAD8ATv6FxYVIiJqNLlluTh39SwuXTiEolOHIT9/HlbJmfDNqkZgDmBcc/fXF9iaoszVEcLTE0Y+ATD37wB9vwDAzw/g/7tbJRYVIiJqUkIIpBel41zWGaTH7EfZhTOQp1yGUXoW7K6WwCsf8MoHzKruvpxcG2Pkezig3McTcv9AmHToDLuOj8LE2b15NoQkwaJCRESSqaipQGpBKpLzkpCREovii2dQm5QIg9R0WGTmwSO3Fn7XAac7nAsDANdMZEhzNsE1d1uUtnWDMqgDnLv0gW9wb5goeSdqXceiQkREWkklVMgqzkJqYSqy0i6g/OxpIC4OJslpsL2cA7fMUrjn3/ljqUgBpDgpke/hCJWfL8xCusDloX5wDOoKGe9ErTNYVIiISGcV5mYi5/QBlMacQO2Fc1AmJMMiJQtOV0uhr6r7NRX6QIajCYq8nAE/fxi184NZ2wDY+oZC6dEWMDFp3o2gu2JRISKilqeqCrmxx3Dl6A4UnzkOeXwCrFKy4ZFdAaN7nNBbaKyHPFtjlDhYo9rJHjJXNyg928HcKwC2fmEwbOcLGPAWA82FRYWIiFqNysoyJEXvRtaJPSg9cxIGiZdgllMA29xyuBSKe57QCwA1cuCajREKXexQ6+UBQ99A2ASHwyKw443LrI2Mmn5DWhEWFSIiavWEEMgvz0NmxkXkJZxByaWLqLqcDNmVDCizcmCWUwibvHK45Yt7XmKdZ2OMUjdHwKstjHzbw8zdG8o2boCjI+DgANjbAwpF82xYC8CiQkREVA9CCOSWXUfyhUPIiT2M0gtngORkmKRlwym7FO3yAMvK+i2r1MwQFbYWqLGzgczRCQbOrjBx9YLC3evGb8b4+PAeSv+PRYWIiOgBlVWXIfF6ApKTTyA39hgq4s9BfikFZpm5sCmuhWMJ4FACOJQCBnc4yfffimzNUdbWDXr+ATAP6QJl+5AbJaZNG0Ama9oN0iIsKkRERE1ECIHiqmJkFmciqzgLmYVXkJ91CWVpl1CVmQaRnQ39nOtQ5hbCpqgaHgWA73XAsfTOy6ww1EehuwOqvdtC4e0HozaeMHHzgtzR6X9fL5mZtZgyw6JCRESkBYori3G54DIS8xKRevkMSs+dBi7GwyzlCtyyyuF3HWiXV78jMlUKPZRam6LSxgq1DnbQc3SCoo0bTL38oPD2Azw9AVdXnbh6iUWFiIhIyxVUFCAxNxGJ2Rdw/dxxVMWdhUFCMkyv5sEivwIOpYBjyY2pPlcuATfucF1gZ4ZSF3vUerhBv50vzHyDYO7fAXKvtoCdnVYclWFRISIi0mHVtdXIKc1Bdkk2skqycP1aKkrSk1GZkYbarAzIcnKguJYHk9xiOOfXwisf8CgADGvvvtxypR6KLAxRbmqISnMjVJmbosbCDCpLCwgrS8isrKFnYwt9GzsobR2htHOEeRsvWNq7Ner23c/nN39vmIiISMsY6BmgjXkbtDFvc+MJn7rHCSGQX5GPtMI07Mi/jNzkcyhPvABxKRnKtEyYZ+bBMacMngVAmyLAqLIWRjmlQM5dTpj5l2OdnRF+POPBN6qBWFSIiIh0lEwmg7WRNayNrNHBsQPgP/S2MdW11cgozsChnCTkXYxGTU42VHm5QH4+ZAWF0C8sgkFhCRTFZTAsLodJSSVMSqthVlYDyzIVKs2lvf0AiwoREVELZqBnAA9LD3hYegA+Eff9+kdq7/F9UhOTS7p2IiIi0moyPT1J18+iQkRERFqLRYWIiIi0FosKERERaS0WFSIiItJaLCpERESktVhUiIiISGuxqBAREZHWYlEhIiIircWiQkRERFqLRYWIiIi0FosKERERaS0WFSIiItJaLCpERESktfSlDvAghBAAgKKiIomTEBERUX3d/Ny++Tl+NzpdVIqLiwEArq6uEichIiKi+1VcXAwLC4u7jpGJ+tQZLaVSqZCZmQkzMzPIZLJGXXZRURFcXV2Rnp4Oc3PzRl22tuG2tlytaXu5rS1Xa9re1rKtQggUFxfD2dkZcvndz0LR6SMqcrkcLi4uTboOc3PzFv2P5Vbc1parNW0vt7Xlak3b2xq29V5HUm7iybRERESktVhUiIiISGuxqNyBUqnErFmzoFQqpY7S5LitLVdr2l5ua8vVmra3NW1rfen0ybRERETUsvGIChEREWktFhUiIiLSWiwqREREpLVYVIiIiEhrsajU4dtvv4WHhwcMDQ0RHh6O48ePSx2pScyePRsymUxj8vPzkzpWo9i/fz8GDx4MZ2dnyGQybNiwQWO+EAIzZ86Ek5MTjIyMEBERgcTERGnCPqB7beu4ceNu288DBgyQJuwDmjdvHjp37gwzMzPY29tj6NChiI+P1xhTUVGBqVOnwsbGBqamphgxYgSuXr0qUeIHU5/t7dmz5237d9KkSRIlbrglS5YgODhY/UNnXbt2xT///KOe35L26722taXs08bCovIvf/zxB9566y3MmjULp0+fRkhICPr374+cnBypozWJwMBAZGVlqaeDBw9KHalRlJaWIiQkBN9++22d8+fPn49vvvkGS5cuxbFjx2BiYoL+/fujoqKimZM+uHttKwAMGDBAYz+vXr26GRM2nn379mHq1Kk4evQodu7cierqavTr1w+lpaXqMW+++Sb+/vtv/Pnnn9i3bx8yMzMxfPhwCVM3XH22FwAmTpyosX/nz58vUeKGc3FxwaeffopTp07h5MmT6N27N4YMGYLz588DaFn79V7bCrSMfdpoBGno0qWLmDp1qvpxbW2tcHZ2FvPmzZMwVdOYNWuWCAkJkTpGkwMgIiMj1Y9VKpVwdHQUCxYsUD9XUFAglEqlWL16tQQJG8+/t1UIIcaOHSuGDBkiSZ6mlpOTIwCIffv2CSFu7EcDAwPx559/qsfExcUJAOLIkSNSxWw0/95eIYTo0aOHeP3116UL1YSsrKzEjz/+2OL3qxD/21YhWvY+bQgeUblFVVUVTp06hYiICPVzcrkcEREROHLkiITJmk5iYiKcnZ3h5eWFMWPGIC0tTepITS4lJQXZ2dka+9nCwgLh4eEtdj9HRUXB3t4evr6+mDx5MnJzc6WO1CgKCwsBANbW1gCAU6dOobq6WmPf+vn5wc3NrUXs239v700rV66Era0t2rdvj+nTp6OsrEyKeI2mtrYWa9asQWlpKbp27dqi9+u/t/WmlrZPH4RO35SwsV2/fh21tbVwcHDQeN7BwQEXL16UKFXTCQ8Px4oVK+Dr64usrCzMmTMHjzzyCM6dOwczMzOp4zWZ7OxsAKhzP9+c15IMGDAAw4cPh6enJ5KTk/Gf//wHAwcOxJEjR6Cnpyd1vAZTqVR444030L17d7Rv3x7AjX2rUChgaWmpMbYl7Nu6thcARo8eDXd3dzg7OyM2Nhbvvfce4uPjsX79egnTNszZs2fRtWtXVFRUwNTUFJGRkQgICEBMTEyL26932lagZe3TxsCi0ooNHDhQ/XdwcDDCw8Ph7u6OtWvXYvz48RImo8b0zDPPqP8OCgpCcHAw2rZti6ioKPTp00fCZA9m6tSpOHfuXIs5r+pe7rS9L730kvrvoKAgODk5oU+fPkhOTkbbtm2bO+YD8fX1RUxMDAoLC7Fu3TqMHTsW+/btkzpWk7jTtgYEBLSofdoY+NXPLWxtbaGnp3fbmeRXr16Fo6OjRKmaj6WlJXx8fJCUlCR1lCZ1c1+21v3s5eUFW1tbnd7Pr7zyCjZv3oy9e/fCxcVF/byjoyOqqqpQUFCgMV7X9+2dtrcu4eHhAKCT+1ehUKBdu3bo2LEj5s2bh5CQEHz99dctcr/eaVvrosv7tDGwqNxCoVCgY8eO2L17t/o5lUqF3bt3a3x32FKVlJQgOTkZTk5OUkdpUp6ennB0dNTYz0VFRTh27Fir2M9XrlxBbm6uTu5nIQReeeUVREZGYs+ePfD09NSY37FjRxgYGGjs2/j4eKSlpenkvr3X9tYlJiYGAHRy//6bSqVCZWVli9uvdbm5rXVpSfu0QaQ+m1fbrFmzRiiVSrFixQpx4cIF8dJLLwlLS0uRnZ0tdbRG9/bbb4uoqCiRkpIiDh06JCIiIoStra3IycmROtoDKy4uFtHR0SI6OloAEAsXLhTR0dEiNTVVCCHEp59+KiwtLcXGjRtFbGysGDJkiPD09BTl5eUSJ79/d9vW4uJiMW3aNHHkyBGRkpIidu3aJcLCwoS3t7eoqKiQOvp9mzx5srCwsBBRUVEiKytLPZWVlanHTJo0Sbi5uYk9e/aIkydPiq5du4quXbtKmLrh7rW9SUlJYu7cueLkyZMiJSVFbNy4UXh5eYlHH31U4uT37/333xf79u0TKSkpIjY2Vrz//vtCJpOJHTt2CCFa1n6927a2pH3aWFhU6rBo0SLh5uYmFAqF6NKlizh69KjUkZrE008/LZycnIRCoRBt2rQRTz/9tEhKSpI6VqPYu3evAHDbNHbsWCHEjUuUZ8yYIRwcHIRSqRR9+vQR8fHx0oZuoLtta1lZmejXr5+ws7MTBgYGwt3dXUycOFFni3dd2wlALF++XD2mvLxcTJkyRVhZWQljY2MxbNgwkZWVJV3oB3Cv7U1LSxOPPvqosLa2FkqlUrRr10688847orCwUNrgDfDiiy8Kd3d3oVAohJ2dnejTp4+6pAjRsvbr3ba1Je3TxiITQojmO35DREREVH88R4WIiIi0FosKERERaS0WFSIiItJaLCpERESktVhUiIiISGuxqBAREZHWYlEhIiIircWiQkRERFqLRYWISIdFRUVBJpPddsM+opaCRYXoAV27dg2TJ0+Gm5sblEolHB0d0b9/fxw6dEg9RiaTYcOGDdKFvA83P/jqmrKzs6WOd5usrCyMHj0aPj4+kMvleOONN+oc9+eff8LPzw+GhoYICgrC1q1bNeYLITBz5kw4OTnByMgIERERSExMbIYtIKK7YVEhekAjRoxAdHQ0fvnlFyQkJGDTpk3o2bMncnNzpY72QOLj45GVlaUx2dvbN9n6qqqqGvS6yspK2NnZ4cMPP0RISEidYw4fPoxRo0Zh/PjxiI6OxtChQzF06FCcO3dOPWb+/Pn45ptvsHTpUhw7dgwmJibo378/KioqGpSLiBqJxPcaItJp+fn5AoCIioq64xh3d3eNG8q5u7ur523YsEGEhoYKpVIpPD09xezZs0V1dbV6PgDx3XffiQEDBghDQ0Ph6ekp/vzzT/X8yspKMXXqVOHo6CiUSqVwc3MTn3zyyQNt082bHObn59c5f/v27UKpVN42/7XXXhO9evVSPz5w4IB4+OGHhaGhoXBxcRGvvvqqKCkp0Xhf5s6dK5577jlhZmYmxo4dK3r16iWmTp2qsdycnBxhYGAgdu3adc/sPXr0EK+//vptz48cOVIMGjRI47nw8HDx8ssvCyFu3KTS0dFRLFiwQD2/oKBAKJVKsXr16juur7a2VnzyySfCw8NDGBoaiuDgYI39c/O93Lx5swgKChJKpVKEh4eLs2fPaixn3bp1IiAgQCgUCuHu7i4+//xzjfkVFRXi3XffFS4uLkKhUIi2bduKH3/8UWMdu3btEh07dhRGRkaia9eu4uLFi+rXx8TEiJ49ewpTU1NhZmYmwsLCxIkTJ+7xbhJpBxYVogdQXV0tTE1NxRtvvCEqKirqHJOTk6O+421WVpbIyckRQgixf/9+YW5uLlasWCGSk5PFjh07hIeHh5g9e7b6tQCEjY2N+OGHH0R8fLz48MMPhZ6enrhw4YIQQogFCxYIV1dXsX//fnH58mVx4MABsWrVqgfapnsVlZqaGuHg4KD+oKzruaSkJGFiYiK+/PJLkZCQIA4dOiRCQ0PFuHHj1K9xd3cX5ubm4vPPPxdJSUkiKSlJrFy5UlhZWWm8lwsXLhQeHh5CpVLdM/udioqrq6v48ssvNZ6bOXOmCA4OFkIIkZycLACI6OhojTGPPvqoeO211+64vv/+97/Cz89PbNu2TSQnJ4vly5cLpVKpLq4330t/f3+xY8cOERsbKx5//HHh4eEhqqqqhBBCnDx5UsjlcjF37lwRHx8vli9fLoyMjDTuCD1y5Ejh6uoq1q9fL5KTk8WuXbvEmjVrNNYRHh4uoqKixPnz58UjjzwiunXrpn59YGCgePbZZ0VcXJxISEgQa9euFTExMfd8P4m0AYsK0QNat26dsLKyEoaGhqJbt25i+vTp4syZMxpjAIjIyEiN5/r06XPb0Y/ffvtNODk5abxu0qRJGmPCw8PF5MmThRBCvPrqq6J37971+hCvr5sffCYmJhpTQECAeszrr78uevfurX7876Ms48ePFy+99JLGcg8cOCDkcrkoLy8XQtwoKkOHDtUYU15eLqysrMQff/yhfi44OFijvN3NnYqKgYHBbQXu22+/Ffb29kIIIQ4dOiQAiMzMTI0xTz31lBg5cmSd66qoqBDGxsbi8OHDGs+PHz9ejBo1Sgjxv/fyZqkQQojc3FxhZGSk3sbRo0eLvn37aizjnXfeUb/f8fHxAoDYuXNnnTluPaJy05YtWwQA9XttZmYmVqxYUefribQdz1EhekAjRoxAZmYmNm3ahAEDBiAqKgphYWFYsWLFXV935swZzJ07F6ampupp4sSJyMrKQllZmXpc165dNV7XtWtXxMXFAQDGjRuHmJgY+Pr64rXXXsOOHTvuuL4DBw5orGvlypV3zXfgwAHExMSop1tPPh0zZgyioqKQmZkJAFi5ciUGDRoES0tL9batWLFCY339+/eHSqVCSkqKejmdOnXSWKehoSGee+45/PzzzwCA06dP49y5cxg3btxds0ohKSkJZWVl6Nu3r8Z2/vrrr0hOTtYYe+s+tLa2hq+vr3ofxsXFoXv37hrju3fvjsTERNTW1iImJgZ6enro0aPHXfMEBwer/3ZycgIA5OTkAADeeustTJgwAREREfj0009vy0ekzfSlDkDUEhgaGqJv377o27cvZsyYgQkTJmDWrFl3/YAtKSnBnDlzMHz48DqXVx9hYWFISUnBP//8g127dmHkyJGIiIjAunXrbhvbqVMnxMTEqB87ODjcddmenp7q4vFvnTt3Rtu2bbFmzRpMnjwZkZGRGsWspKQEL7/8Ml577bXbXuvm5qb+28TE5Lb5EyZMQIcOHXDlyhUsX74cvXv3hru7+12z3oujoyOuXr2q8dzVq1fh6Oionn/zuZsf8jcfd+jQoc5llpSUAAC2bNmCNm3aaMxTKpUPlPdWRkZG9RpnYGCg/lsmkwEAVCoVAGD27NkYPXo0tmzZgn/++QezZs3CmjVrMGzYsEbLSdRUWFSImkBAQIDG5cgGBgaora3VGBMWFob4+Hi0a9furss6evQonn/+eY3HoaGh6sfm5uZ4+umn8fTTT+PJJ5/EgAEDkJeXB2tra43lGBkZ3XNd92PMmDFYuXIlXFxcIJfLMWjQIPW8sLAwXLhwoUHrCwoKQqdOnfDDDz9g1apVWLx48QNn7dq1K3bv3q1x6fLOnTvVRzo8PT3h6OiI3bt3q4tJUVERjh07hsmTJ9e5zICAACiVSqSlpd3zaMfRo0fVBS0/Px8JCQnw9/cHAPj7+2tcyg4Ahw4dgo+PD/T09BAUFASVSoV9+/YhIiKiIZsPAPDx8YGPjw/efPNNjBo1CsuXL2dRId0g9XdPRLrs+vXrolevXuK3334TZ86cEZcuXRJr164VDg4O4sUXX1SP8/b2FpMnTxZZWVkiLy9PCCHEtm3bhL6+vpg9e7Y4d+6cuHDhgli9erX44IMP1K8DIGxtbcVPP/0k4uPjxcyZM4VcLhfnz58XQgjxxRdfiFWrVom4uDgRHx8vxo8fLxwdHUVtbW2Dt+nmOQ/x8fEiKytLY7p5AqgQQiQmJgoAIjg4WIwfP15jGWfOnBFGRkZi6tSpIjo6WiQkJIgNGzZoXNHj7u5+2wmuNy1btkwoFAphZWWlPs/ibqKjo0V0dLTo2LGjGD16tIiOjla/R0LcOAdFX19ffP755yIuLk7MmjVLGBgYaFx98+mnnwpLS0uxceNGERsbK4YMGSI8PT3vuv4PPvhA2NjYiBUrVoikpCRx6tQp8c0336jPB7n5XgYGBopdu3aJs2fPiieeeEK4ubmJyspKIYQQp06d0jiZdsWKFbedTDtu3Djh6uoqIiMjxaVLl8TevXvV57jUdfJzdHS0ACBSUlJEWVmZmDp1qti7d6+4fPmyOHjwoGjbtq1499137/m+EmkDFhWiB1BRUSHef/99ERYWJiwsLISxsbHw9fUVH374oSgrK1OP27Rpk2jXrp3Q19fXuDx527Ztolu3bsLIyEiYm5uLLl26iGXLlqnnAxDffvut6Nu3r1AqlcLDw0PjRNNly5aJDh06CBMTE2Fubi769OkjTp8+/UDbdPODr67pyJEjGmO7dOkiAIg9e/bctpzjx4+Lvn37ClNTU2FiYiKCg4PFxx9/rJ5/t6JSXFwsjI2NxZQpU+qVua6st77PQgixdu1a4ePjIxQKhQgMDBRbtmzRmK9SqcSMGTOEg4ODUCqVok+fPiI+Pv6u61WpVOKrr74Svr6+wsDAQNjZ2Yn+/fuLffv2CSH+917+/fffIjAwUCgUCtGlS5fbTra+eXmygYGBcHNz07hMWogbJxm/+eabwsnJSSgUCtGuXTvx888/a6zjTkWlsrJSPPPMM8LV1VUoFArh7OwsXnnllXoVQCJtIBNCiOY8gkNE9SeTyRAZGYmhQ4dKHaVZXb58GW3btsWJEycQFhYmdZwGi4qKQq9evZCfn3/H832I6O54jgoRaY3q6mrk5ubiww8/xEMPPaTTJYWIGgcvTyYirXHo0CE4OTnhxIkTWLp0qdRxiEgL8KsfIiIi0lo8okJERERai0WFiIiItBaLChEREWktFhUiIiLSWiwqREREpLVYVIiIiEhrsagQERGR1mJRISIiIq31f1/Qw/C3tyz5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "train_loss_list_converted = [i.cpu().detach() for i in train_loss_list]\n",
        "validation_loss_list_converted = [i.cpu().detach() for i in validation_loss_list]\n",
        "\n",
        "plt.plot(train_loss_list_converted, 'g', label='train_loss')\n",
        "plt.plot(validation_loss_list_converted, 'r', label='validation_loss')\n",
        "plt.xlabel(\"Steps - Every 100 epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2ocyyQwkjK6"
      },
      "source": [
        "## Step 10: Run SLM Inference on our trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-20T15:45:44.322237Z",
          "iopub.status.busy": "2024-06-20T15:45:44.321316Z",
          "iopub.status.idle": "2024-06-20T15:45:46.887084Z",
          "shell.execute_reply": "2024-06-20T15:45:46.886126Z",
          "shell.execute_reply.started": "2024-06-20T15:45:44.322203Z"
        },
        "id": "06NrdWKdkjK7",
        "outputId": "88525b71-a4ab-4867-b320-f6e0b23346ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Load the model\n",
        "model = GPT(config)  # re-create the model with same config\n",
        "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "best_model_params_path = \"best_model_params.pt\"\n",
        "model.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device))) # load best model states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-20T15:44:36.64937Z",
          "iopub.status.busy": "2024-06-20T15:44:36.64896Z",
          "iopub.status.idle": "2024-06-20T15:45:14.425576Z",
          "shell.execute_reply": "2024-06-20T15:45:14.424712Z",
          "shell.execute_reply.started": "2024-06-20T15:44:36.649341Z"
        },
        "id": "K8PgWXb-kjK7",
        "outputId": "486f01cd-acf7-431d-cfa7-2f36b600dee6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once upon a time there was a pumpkin. It was very special. The pumpkin were very happy.\n",
            "\n",
            "One day, a kind lady came to the store to you. The delicious corn helped the bird play games alone. She had 2 laser soldiers who lived in the forest.\n",
            "\n",
            "The lady felt ashamed. Her friend said, \"Don't worry, I need a board!\"\n",
            "\n",
            "The witch said, \"I found it under the garden. TheyIt's important to help others and Dad do it. We need to be careful and be careful.\" The lady smiled and felt happy on herself. \n",
            "\n",
            " endAlright, the smell of the beautiful water, but it will take the more dimroom in the water.Once upon a time there was a little girl named Lily. She had a smelly coat with something very loud. One day, she knew she needed to explore more. It was a very special kind of him. \n",
            "\n",
            "Later that day, Lily went to the park and they saw many beautiful flowers she wanted\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Once upon a time there was a pumpkin.\"\n",
        "context = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\n",
        "y = model.generate(context, 200)\n",
        "print(enc.decode(y.squeeze().tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZsL_mONRZAO",
        "outputId": "df3f6ed6-858a-447d-8beb-9c49479bd039"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A little girl went to the woods and she found a basket for her. In one he enjoyed the great basket and the tasty treats tall. Then, she decided to go home and the picnic.\n",
            "\n",
            "As they walked, the little girl was getting tired and didn't want to drink. She opened her pocket to her room and got out. She was would open their new diary! She had a shower and a hug, so she pulled out a big, feeling warm and warm. She hope even when it was time to eat from the fun to eat!Once upon a time there was a little girl named Abbie. Benny loved to know what powers. Her father argued and walked for a after her. \n",
            "\n",
            "When he got there, Katie got excited and started to feel very tired. She said please to the hospital but sometimes he didn't have enough dessert. He sighed and decided to go home.\n",
            "\n",
            "Bubbles was so happy and didn't like Freddy. He stayed away from the doctor and kept walking.\n"
          ]
        }
      ],
      "source": [
        "sentence = \"A little girl went to the woods\"\n",
        "context = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\n",
        "y = model.generate(context, 200)\n",
        "print(enc.decode(y.squeeze().tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_2WjvUszhIe"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30732,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}